<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sharp-rookie.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

<script> 
   (function(){
          if(''){
              if (prompt('请输入文章密码') !== ''){
                  alert('密码错误！');
                  history.back();
              }
          }
      })();
  </script>
  <meta name="description" content="这篇文章提出了一种智能聚合 RAT 接入 (SARA) 策略，旨在最大限度地提高长期网络吞吐量，同时满足各种流量服务质量 (QoS) 要求 模型中考虑了具有不同 QoS 要求的用户访问具有共存蜂窝 WiFi 的异构网络的场景。为了在如此复杂和动态的环境中满足各种流量 QoS 要求的同时最大化系统吞吐量，文章利用多智能体强化学习通过感知动态信道状态和流量QoS 要求来执行 RAT 选择以及针对单个用">
<meta property="og:type" content="website">
<meta property="og:title" content="基于多智能体强化学习的多RAT访问策略&amp;资源调度">
<meta property="og:url" content="https://sharp-rookie.github.io/papers/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84mart%20Multi-RAT%20Access.html">
<meta property="og:site_name" content="最忆是江南">
<meta property="og:description" content="这篇文章提出了一种智能聚合 RAT 接入 (SARA) 策略，旨在最大限度地提高长期网络吞吐量，同时满足各种流量服务质量 (QoS) 要求 模型中考虑了具有不同 QoS 要求的用户访问具有共存蜂窝 WiFi 的异构网络的场景。为了在如此复杂和动态的环境中满足各种流量 QoS 要求的同时最大化系统吞吐量，文章利用多智能体强化学习通过感知动态信道状态和流量QoS 要求来执行 RAT 选择以及针对单个用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311092754.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311092754.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311095402.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311095555.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311100004.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311103737.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311112301.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311112322.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311104903.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311105658.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311110418.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311110624.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311134521.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311141515.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311142248.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311142838.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311143323.png">
<meta property="article:published_time" content="2022-04-25T03:39:28.357Z">
<meta property="article:modified_time" content="2022-04-25T03:39:28.357Z">
<meta property="article:author" content="Lrk612">
<meta property="article:tag" content="5G">
<meta property="article:tag" content="Reinforcement Learning">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="O-RAN">
<meta property="article:tag" content="Mutli-Agent RL">
<meta property="article:tag" content="Resourse Management">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220311092754.png">

<link rel="canonical" href="https://sharp-rookie.github.io/papers/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84mart%20Multi-RAT%20Access">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>基于多智能体强化学习的多RAT访问策略&资源调度 | 最忆是江南
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
        <a target="_blank" rel="noopener" href="https://github.com/Sharp-rookie" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">最忆是江南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Love actually is all around</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-papers">

    <a href="/papers/" rel="section"><i class="book fa-fw"></i>论文阅读</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th-list fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-friendlink">

    <a href="/friendlink/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="zh-CN">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">基于多智能体强化学习的多RAT访问策略&资源调度
</h1>

<div class="post-meta">
  

</div>

</header>

      
      
      
      <div class="post-body">
          <p>这篇文章提出了一种智能聚合 RAT 接入 (SARA) 策略，旨在最大限度地提高长期网络吞吐量，同时满足各种流量服务质量 (QoS) 要求</p>
<p>模型中考虑了具有不同 QoS 要求的用户访问具有共存蜂窝 WiFi 的异构网络的场景。为了在如此复杂和动态的环境中<strong>满足各种流量 QoS 要求的同时最大化系统吞吐量</strong>，文章利用<strong>多智能体强化学习</strong>通过<strong>感知动态信道状态</strong>和<strong>流量QoS 要求</strong>来执行 <strong>RAT 选择</strong>以及针对单个用户访问请求的<strong>资源分配</strong>。</p>
<p>在 SARA（文章算法）中，先使用了 Nash Q-learning 提供一组可行的 RAT 选择策略，同时减少学习过程中的策略空间，然后使用基于蒙特卡洛树搜索 (MCTS) 的 Q-learning 进行资源分配。数值结果表明，通过使用 SARA 算法，网络吞吐量可以最大化，同时满足各种流量 QoS 要求，搜索次数有限。对于批量到达访问请求，可以获得次优解决方案，因为为了实现全局最优会产生高计算复杂度</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311092754.png" alt="image-20220311092753981" style="zoom:55%;" />

<p><strong>原文</strong></p>
<p><a target="_blank" rel="noopener" href="https://lrk612.com/resources/Smart%20Multi-RAT%20Access%20Based%20on%20MultiagentReinforcement%20Learning.pdf">Smart Multi-RAT Access Based on Multiagent Reinforcement Learning</a></p>
<span id="more"></span>

<p>&nbsp;</p>
<h2 id="问题导向及现有研究"><a href="#问题导向及现有研究" class="headerlink" title="问题导向及现有研究"></a>问题导向及现有研究</h2><h3 id="多-RAT-的背景"><a href="#多-RAT-的背景" class="headerlink" title="多 RAT 的背景"></a>多 RAT 的背景</h3><p>根据思科视觉网络指数 [1]，移动流量已经占据了大数据集的很大一部分。为了满足下一代无线网络（5G）不断增长的移动流量需求，<strong>网络容量</strong>和<strong>用户接入效率</strong>都需要大幅度提高</p>
<p>在一定程度上，蜂窝网络的容量可以通过缩小蜂窝尺寸 [2] 显着增加，这被称为<strong>网络致密化</strong>。具体而言，密集部署的小型蜂窝基站 (SBS) 减轻了过载宏蜂窝基站的负担，并且已经进行了大量研究和开发以有效地将流量从宏蜂窝转移到小型蜂窝 [3]、[4]。然而，由于小区与相邻基站之间存在严重的同频干扰，阻碍了小区基站的大规模部署。随着网络负载和频谱需求的快速增长，蜂窝网络将无法满足所有相关的性能要求[5]。作为蜂窝网络的补充和共存无线电接入技术 (RAT)，在<strong>免许可频段运行的 WiFi 热点</strong>的部署现在几乎无处不在。由于 WiFi 承担了蜂窝网络用户数据承载的一些责任，因此它被认为是为蜂窝网络提供额外频谱资源的重要候选者 [6]。使用<strong>多 RAT</strong> 的所有频谱共享成为 5G 及以后的必然解决方案 [7]</p>
<h3 id="多-RAT-的问题-与-AI机遇"><a href="#多-RAT-的问题-与-AI机遇" class="headerlink" title="多 RAT 的问题 与 AI机遇"></a>多 RAT 的问题 与 AI机遇</h3><p>由于跨域管理的复杂性和用户应用程序的不同 QoS 要求 [8]，多 RAT 接入中的访问控制和资源调度具有挑战性。考虑到多 RAT 访问的最佳决策制定困难，最近出现的人工智能 (AI) 技术，如机器学习，提供了一种有效的工具来解决动态和复杂环境中的问题。机器学习使计算机无需明确编程即可学习 [9]。在传统的机器学习机制中，强化学习 (RL) 可以激发智能体学习变化并找到潜在的解决方案。通过与环境交互，RL 成为在不确定性下进行顺序决策的强大工具 [10]。在底层多制式接入场景中，决策因素是动态的，因为请求接入的 UE 数量，每个用户设备 (UE) 的 QoS 要求可能随时间而变化，尤其是无线信道容易出错和时变。 RL 允许代理及时感知网络流量、用户需求等的变化，从而智能地协调 UE 和 BS 的战略行为</p>
<h3 id="文章工作内容"><a href="#文章工作内容" class="headerlink" title="文章工作内容"></a>文章工作内容</h3><p>这篇文章提出了一种基于多智能体强化学习的<strong>智能聚合 RAT 访问（SARA）策略</strong>来解决多 RAT 访问问题，旨在最大化网络吞吐量，同时保证 HetNets 中不同的 UE 流量 QoS 要求</p>
<p>具体而言，文章构建了一个<strong>基于半马尔可夫决策过程（SMDP）的分层决策框架（HDF）</strong>，它由<strong>RAT信道选择过程（RSP）</strong>和<strong>资源分配过程（RAP）</strong>组成</p>
<p>考虑到有多个智能体做出决策，并且网络状态之间的先验转移概率通常不可用，文章使用Model-free多智能体 RL [12] 来解决这个 SMDP 问题。在 RSP 中，由于对特定 UE 的子流的决策过程构成了一个<strong>同步博弈</strong>，我们使用 <strong>Nash Q-learning</strong> 来解决这个问题 [13]，并获得了一组可行的访问策略，可以避免访问冲突和子流的乱序。在 RAP 中，我们采用<strong>基于蒙特卡洛树搜索 (MCTS) 的 Q-Learning</strong> 算法从候选策略集中搜索最优策略，以在满足 QoS 要求的同时最大化系统吞吐量。 MCTS 搜索的策略随着学习过程[14]不断改进，最终可以在有限的搜索步骤中完成最优解。此外，学习搜索可以随时终止，以获得“最新”的最佳策略，以满足特定应用的时效性。</p>
<h3 id="相关研究"><a href="#相关研究" class="headerlink" title="相关研究"></a>相关研究</h3><h4 id="授权和非授权频段的组合机制"><a href="#授权和非授权频段的组合机制" class="headerlink" title="授权和非授权频段的组合机制"></a>授权和非授权频段的组合机制</h4><p>授权和非授权频段的组合机制包括：</p>
<ul>
<li>非授权频谱中的 LTE (LTE-U)</li>
<li>授权辅助接入 (LAA)</li>
<li>LTE-WLAN 无线电级聚合 (LWA) </li>
<li>……</li>
</ul>
<p>LAA 和 LTE-U 被提出用于在 5 Ghz 非授权频段提供载波级无线服务，其中非授权载波用作 LTE 载波聚合框架中的次要分量载波</p>
<p>与未授权频段中的 802.11 WiFi 相比，LTE 具有改进的链路性能、介质访问控制、移动性管理和出色的覆盖范围等优势，因此成为更好的 RAT</p>
<p>然而，如果 WiFi 总是占用未授权频段，因为其使用了先听后说 (LBT) 方案，会导致 LAA 的性能很差</p>
<p>此外，LTE-U中没有采用LBT，导致了其与 WiFi 共存的不公平性</p>
<p>由此可以看出，在 LAA 和 LTE-U 中，LTE 和 WiFi 之间的干扰是不可避免的，也是不可忽视的。 <strong>LWA</strong> 是无线电接入网络 (RAN) 中的一种数据聚合方案，其中数据包被安排在 LTE 和 WiFi 无线电链路上提供服务。每个链路的调度决策可以基于实时信道条件在分组时间级别做出。 LWA 的优势在于它可以在两个链路上提供更好的控制和资源利用。文章提出的 Multi-RAT 访问控制是基于 LWA 机制的。</p>
<h4 id="通过-WiFi-的-RAT-进行流量卸载"><a href="#通过-WiFi-的-RAT-进行流量卸载" class="headerlink" title="通过 WiFi 的 RAT 进行流量卸载"></a>通过 WiFi 的 RAT 进行流量卸载</h4><p>通过 WiFi 的 RAT 进行流量卸载通常被建模为一个<strong>优化问题</strong>，旨在有效地从蜂窝中卸载流量，并从两个频段为 UE 优化分配信道资源。</p>
<p>[16] 的作者考虑了几种未授权频段的利用机制，并提出了一种优化模型，其目标是最大化小型蜂窝用户的吞吐量，同时将小型蜂窝对宏蜂窝的干扰保持在预定义的阈值以下</p>
<p>[17]的作者提出了一种小小区中许可和非许可频段的动态切换和聚合方案，这也被表述为一个优化问题</p>
<p>然而，[16] 和 [17] 中提出的算法似乎在复杂且时变的环境中没有很好的适应性，因为作者忽略了可能随时请求服务的各种类型的 UE 流量。需要针对不同QoS要求的业务流设计更灵活、更公平的资源分配算法，以提高系统的长期吞吐量</p>
<h4 id="强化学习和半马尔可夫决策过程"><a href="#强化学习和半马尔可夫决策过程" class="headerlink" title="强化学习和半马尔可夫决策过程"></a>强化学习和半马尔可夫决策过程</h4><p>最近，强化学习和半马尔可夫决策过程已被应用于解决 RAT 选择和资源分配问题。网络的关键驱动力是在满足用户偏好的同时最大化网络吞吐量</p>
<p>[18] 的作者提出了一种网络辅助 RAT 接入方法，其中 BS 向移动用户发送全球网络信息，以帮助用户做出决策，不仅取决于他们自己的偏好，还取决于手机的整体性能。网络。在某些情况下，用户之间存在资源分配游戏，因为他们竞争有限的网络资源</p>
<p>[19] 的作者将 D2D 用户的联合信道分配和功率控制问题建模为两个游戏，并用多智能体Q-Learning算法很好地解决</p>
<p>在[18]和[20]中，网络选择问题被建模为一个 SMDP，通过使用Q-learning算法来解决。结果表明其可以显着提高网络性能，并且 RL 在随机环境中表现良好。然而，每个代理的动作空间都很大，因此需要很长的搜索时间才能获得全局优化结果。因此，在使用 RL 算法时，降低计算复杂度至关重要，尤其是在时变动态场景中</p>
<p>&nbsp;</p>
<h2 id="Part-2：-LTE-WIFI-聚合——系统模型"><a href="#Part-2：-LTE-WIFI-聚合——系统模型" class="headerlink" title="Part 2： LTE-WIFI 聚合——系统模型"></a>Part 2： LTE-WIFI 聚合——系统模型</h2><h3 id="场景描述"><a href="#场景描述" class="headerlink" title="场景描述"></a>场景描述</h3><p>文章关注蜂窝小基站（SBS）和 WiFi 接入点（AP）共存的场景，如图1所示。假设相邻的 SBS 和 WiFi AP 使用固定和正交的信道资源来避免干扰。 UE 配备了蜂窝和 WiFi 接口，可以从任一 RAT请求数据 [21]。如图 1(a) 所示，Legacy HetNet 用于比较目的，其中 SBS 与 WiFi AP 没有合作，这意味着数据传输是从蜂窝或 WiFi 接口请求的。在图 1(b) 中，下一代网络基站 (xGBS) 通过标准化的 LTE-WLAN 连接（由 Rel-13 中的 3GPP 标准化）[22] 聚合蜂窝 SBS 和 WiFi AP。xGBS 充当数据平面和控制平面的锚节点，并通过常规 S1 接口连接到核心网络。</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311092754.png" alt="image-20220311092753981" style="zoom:70%;" />

<center>图 1</center>

<p>由于 UE 在移动性和数据请求中行为的随机性，网络接入确实是一个时变的动态场景。文章将时间划分为执行 RAT 选择和资源分配决策的帧，这被定义为“<strong>决策时间帧 (DTF)<strong>”。为了不违反 QoS 要求，DTF 的长度被设置为小于流量的最小延迟容限。如果到达流都是对延迟不敏感的服务，则可以将 DTF 的长度设置得更长。换句话说，DTF 的长度可以在不同的决策过程中有所不同，目的是在</strong>保证 QoS 要求</strong>的同时提高<strong>信道资源的利用率</strong>。不失一般性，我们假设在 DTF 中，网络拓扑可以被认为是静态的。文章中，BS 能够获取全球网络信息，包括 UE 服务的 QoS 要求和信道负载信息。多种RAT的集成必须在 xGBS 的统一管理下智能地完成，目的是在兼顾 UE 和网络运营商的偏好的同时，灵活地将两种RAT的资源分配给用户</p>
<h3 id="信道接入模型"><a href="#信道接入模型" class="headerlink" title="信道接入模型"></a>信道接入模型</h3><p>在 LTE 的许可频段上，通过在下行链路上使用正交频分多址 (OFDMA) 来执行媒体接入。许可频段上的频谱被划分为<strong>时频无线电块 (RB)<strong>，文章其余部分将其称为</strong>子信道</strong>。此外，文章假设传输功率均匀分配给许可频段上的每个子信道。在未授权频段上，文章考虑 IEEE WiFi 802.11 的 RAT</p>
<p>由于 IEEE WiFi 802.11 中使用的先听后说 (LBT) 机制，WiFi 一次只能服务一个终端或聚合 MAC 协议数据单元 (A-MPDU) [23] 来传输数据，因此 UE 共享相同的通过 TDM 的 WiFi 频段。为了保护动态网络环境中正在进行的会话，应用了准入控制策略。更详细地说，为了不损害正在进行的会话的 QoS，新到达的流需要等待，直到有空闲的信道资源进行传输</p>
<p>文章假设 XGBS 中有 λ 个 LTE 子信道和 1 个 WiFi 信道。允许将流拆分为多个子流，这些子流可以使用 <code>γ (1&lt; γ &lt; λ + 1)</code> 个不连续（频谱）信道进行传输以满足其 QoS 要求。此外，在多 RAT 接入控制方案中，通过调度算法的动态编排，允许 UE 使用多个 RAT 在多个 DTF 中传输</p>
<p>&nbsp;</p>
<h2 id="Part3：问题建模与分析"><a href="#Part3：问题建模与分析" class="headerlink" title="Part3：问题建模与分析"></a>Part3：问题建模与分析</h2><p>在多 RAT 接入问题中，网络运营商追求最大化系<strong>统吞吐量</strong>，而 UE 则倾向于最大化其<strong>传输速率</strong>并满足其 <strong>QoS 要求</strong>。因此，文章分别从网络运营商和 UE 的角度制定了最优的多 RAT 接入问题</p>
<h3 id="运营商角度"><a href="#运营商角度" class="headerlink" title="运营商角度"></a>运营商角度</h3><p>从网络运营商的角度来看，网络吞吐量可以通过增加每个 DTF 中所有 UE 的授权和非授权频段的下行链路吞吐量总和来提高。考虑分别具有 <code>N1、···、Nm</code> 个信道（或子信道）的 m RAT。第 <code>i</code> 个 RAT 的第 <code>j</code> 个信道的带宽记为 <code>Bij</code>，其能提供 <code>Uij</code> 的吞吐量。现在的问题是从每个 RAT 中准确地选择一个信道，以便在带宽总容量 <code>^Bi</code> 的情况下使吞吐量最大化。可以将第 <code>k</code> 个 DTF 中的长期系统平均吞吐量 <code>U</code> 最大化问题表述为</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311095402.png" alt="image-20220311095402027" style="zoom:75%;" />

<p>其中 <code>cij</code> 是一个二进制变量，表示是否在传输中使用第 <code>i</code> 个 RAT 的第 <code>j</code> 个信道。 <code>m</code> 值固定等于 2，分别对应许可和非许可频段上运行的 LTE 和 WiFi 的 RAT。约束（1.1）规定分配的带宽不能超过许可和非许可频段分别可以提供的备用带宽。约束 (1.2) 表明将选择至少一个通道（或子通道）来服务于交通流</p>
<h3 id="UE角度"><a href="#UE角度" class="headerlink" title="UE角度"></a>UE角度</h3><p>从UE的角度来看，多 RAT 接入问题确实是一个资源分配问题，随着网络资源的稀缺，各个UE之间存在潜在的博弈。由于网络环境随时间变化，动态灵活的资源分配机制是必不可少的。因此，从 UE 角度来看，最优多 RAT 接入问题可以表述为在保证 QoS 约束的情况下最大化 UE 的平均传输速率：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311095555.png" alt="image-20220311095555006" style="zoom:75%;" />

<p>其中 <code>N</code> 是当前 DTF 中的 UE 数量，<code>Kn</code> 是系统操作中 UE <code>n</code> 的特定应用的 DTF 总数，并且 <code>Rn (k) = (1 -Ln (k))*Sn (k)/ Tn (k)</code> 是 UE <code>n</code> 在第 <code>k</code> 个 DTF 中特定应用的传输速率，其中 <code>Sn (k)</code> 是流的大小，<code>Tn (k)</code> 是流的传输时间（包括排队延迟），<code>Ln (k )</code> 是丢包概率</p>
<p>文章使用 <code>Hn (k)</code> 来表示由第 <code>k</code> 个 DTF 中的流的子流选择的 LTE 子信道集合，并使用二进制值 <code>ω(k)</code> 来表示 WiFi 信道是否参与了第 <code>k</code> 个 DTF 中的传输过程。<code>Hn (k)</code> 等于空集意味着 LTE 子信道不是参与第 <code>k</code> 个 DTF 中流的传输过程</p>
<p>由此，<code>Sn(k)</code> 可表示为：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311100004.png" alt="image-20220311100004325" style="zoom:95%;" />

<p>其中，<code>sLh</code> 和 <code>sw</code> 分别是分配给 LTE 的子信道 <code>h</code> 和WiFI信道的子流大小</p>
<blockquote>
<p>文章调度机制的“智能”就体现在 UE 的 RAT 接入模式（使用哪个 LTE 子信道或 WiFi 信道）是根据网络的时变环境在不同的 DTF 中动态确定的</p>
</blockquote>
<p>约束（2.1）中，<code>Qn</code> 是分配的资源与预期性能之间的 QoS 函数映射，<code>Qn_th</code> 是 UE <code>n</code> 的 QoS 要求阈值。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>文章认为上述问题（1）和（2）组合的多RAT访问控制问题可以映射到<strong>多选维度背包问题（MCKP）</strong>。 MCKP 在计算上比背包更难。即使对于维度等于 2 的情况，该问题也没有完全多项式时间近似方案 [24]，因此，这是一个  NP-hard 问题</p>
<p>考虑到网络动态、UE 的移动、不同的信道状态、不同的 QoS 要求等，根据单个 UE 的 QoS 要求为最大化长期平均系统吞吐量的多 RAT 访问控制问题开发一个最优解决方案是非常具有挑战性的。由于这是一个具有动态输入的随机优化问题，因此文章采用具有多智能体强化学习方法的半马尔可夫决策过程（SMDP）来解决</p>
<p>&nbsp;</p>
<h2 id="Part4：多RAT访问控制的半马尔可夫决策过程"><a href="#Part4：多RAT访问控制的半马尔可夫决策过程" class="headerlink" title="Part4：多RAT访问控制的半马尔可夫决策过程"></a>Part4：多RAT访问控制的半马尔可夫决策过程</h2><h3 id="基于-SMDP-的分层决策框架"><a href="#基于-SMDP-的分层决策框架" class="headerlink" title="基于 SMDP 的分层决策框架"></a>基于 SMDP 的分层决策框架</h3><p>由于多 RAT 访问中的 RAT 选择和资源分配可以被视为两个连续的过程，文章提出了一种基于 SMDP 的分层决策框架（HDF）来解决联合 RAT 选择和资源分配问题</p>
<p>图 2 显示了 HDF 的框图。在 HDF 中，一旦代理（UE）做出决定（包括 RAT 选择和相应的资源分配），网络状态可能会发生变化，更新后的状态和评估函数给出的奖励是对控制器的反馈。这种反复试验的过程会直到奖励收敛或时间结束，从而推动决策朝着网络预期的方向发展</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311103737.png" alt="image-20220311103737096" style="zoom:60%;" />

<center>图 2</center>

<p>具体来说，控制器在 HDF 中采用两阶段决策过程，包括 RAT信道选择过程 (RSP) 和资源分配过程 (RAP)，以实现多 RAT 接入</p>
<p>第 1 阶段的 RSP 游戏在 HDF 的内循环中执行，其中需要将信道状态信息发送给控制器（BS）以进行决策。在 RSP 博弈中，尝试通过考虑（3）的约束来减少每个用户的可行动作空间，以加快收敛速度。 RSP 博弈中的 Nash Q-learning 收敛后，得到多组可行的 RAT/channels 并输出到 Stage 2 的 RAP 博弈进行另一轮学习过程</p>
<p>在第二阶段的 RAP 博弈中，在 HDF 的外部循环中执行，每个代理采用 P&amp;V MCTS 算法搜索资源分配策略，以最大化其吞吐量，受带宽资源和 QoS 要求的约束。在 RAP 中，还利用了 UE 偏好和信道状态信息</p>
<hr>
<p>将第 <code>k</code> 个 DTF 中信道 <code>i</code> 的状态定义为向量 <code>ci (k) = (μi (k), N i (k), li (k))</code>，其中 <code>μi (k)</code> 是第 <code>k</code> 个 DTF中的信道 <code>i</code> 。注意，μi (k) 的值反映了信道状态的影响，包括路径损耗、衰落。 <code>Ni (k)</code> 是驻留在通道 <code>i</code> 中的子流的数量，<code>li (k) = ∑zij</code> 表示通道 <code>i</code> 的负载，其中 <code>zij</code> 是信道 <code>i</code> 中尚未服务的流 <code>j</code> 的子流。此外，令第 <code>k</code> 个 DTF 中的整体通道状态表示为 <code>C(k) = ( c1(k), c2(k),···, cN c (k))</code></p>
<p>SMDP 中的动作表示控制器在特定网络状态下采用的策略。由于信道由 xGBS 控制，并且假设 DTF 内的无线电条件不变，因此在 DTF 开始时，新到达流在信道 <code>i</code> 的排队延迟可以表示为 <code>li (k)/μi (k)</code>。流的可行通道按照访问排队时间的非递减顺序 <code>(1, 2, ..., Nc )</code> 进行排序。将流 <code>n</code> 的动作定义为 <code>An (γn , Λn ), ∀n ∈[1, N ]</code>，其中 <code>γn</code> 表示将其分成的子流的数量，<code>Λn</code> 表示通道选择策略集</p>
<p>在多RAT模型中，信道状态随着时间的推移而变化，以及流量的到达和离开。可以得到，通道 <code>i</code> 的状态由 <code>ci (k) = &#123;μi (k), N i (k), ∑zij&#125;</code> 变为 <code>ci (k + 1) = &#123;μi (k + 1), N i (k + 1), ∑zij&#125;</code></p>
<p>RSP 或 RAP 策略通过使用评估函数来确定奖励，评估函数反映了设计目标。下面详细说明 RSP 和 RAP 评估函数</p>
<h3 id="RAT信道选择过程的评估函数"><a href="#RAT信道选择过程的评估函数" class="headerlink" title="RAT信道选择过程的评估函数"></a>RAT信道选择过程的评估函数</h3><p>由于允许 UE 的数据流使用多个信道进行传输，如果同时选择相同的子信道或 WiFi 信道，可能会发生接入冲突，导致接入失败。而且，由于通道的状态不同，通过不同子通道传输的子流可能会乱序到达终端</p>
<p>考虑一个流级的数据包重排序过程，终端子流的频繁重排序将导致不可忽略的时间延迟。文章设计的多RAT访问控制算法需要应对这些问题</p>
<p>如前所述，在 RSP 过程中可以将一个数据流拆分为多个子流。让 UE <code>n</code> 的子流 <code>(1, 2, ..., γn)</code> 在模型中定义为 <strong>agent</strong>，它们在 RSP 中做出同时选择 RAT 和信道的决策。将 <code>πn = (a1, ..., aγn)</code> 定义为这些子流的联合通道选择策略，其中 <code>aj</code> 表示代理 <code>j</code> 选择的通道的序号。使用函数 <code>coll_j(s, πn)</code> 和 <code>dis_j(s, πn)</code> 来评估智能体 <code>j</code> 在状态 <code>s</code> 的策略集 <code>πn</code>，目的是分别避免碰撞和混乱</p>
<p>然后定义代理 <code>j</code> 的 RSP 评估函数，用 <code>RSP_j (s, πn)</code> 表示：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311112301.png" alt="image-20220311112301764" style="zoom:90%;" />

<p>其中</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311112322.png" alt="image-20220311112322220" style="zoom:80%;" />

<p>其中 <code>σ</code> 和 <code>δ</code> 是两个大于零的常数</p>
<p>一方面，对于 <code>coll_j(s, πn)</code>，假设代理 <code>j</code> 和 <code>k</code> 分别采用通道选择策略 <code>aj</code> 和 <code>ak</code>。如果 <code>aj</code> = <code>ak</code> 则发生冲突，访问失败，将 <code>-σ</code> 反馈给代理 <code>j</code> 作为该合作策略的评估值</p>
<p>另一方面，对于 <code>dis_j(s, πn)</code>，当每次在选择通道之前按排队时间对这些通道进行排序时，如果代理 <code>j</code> 和 <code>l</code> (j &lt; l ) 分别采取动作 <code>aj</code> 和 <code>al</code> (aj &gt; al )，子流的到达可能是无序的，从而在终端重新排序会产生一些费用，因此将 <code>-δ</code> 反馈给代理 <code>j</code> 作为该合作策略的评估值</p>
<h3 id="资源分配的过程的评估函数"><a href="#资源分配的过程的评估函数" class="headerlink" title="资源分配的过程的评估函数"></a>资源分配的过程的评估函数</h3><p>设计目标是在用户 QoS 要求的约束下最大化长期网络吞吐量，指导代理选择网络期望的策略。从检查特定 DTF 中流量 <code>n</code> 的瞬时传输率开始。将 <code>^Tn</code> 定义为流 <code>n</code> 的传输延迟，因此 (2) 中的 Sn /Tn 可以表示为 <code>(Sn / ^Tn ) ·( ^Tn /Tn )</code>。使用 <code>Bn</code> 来表示 <code>Sn / ^Tn</code> ，它是流 <code>n</code> 所需的带宽。此外，我们在(2)两边取自然对数：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311104903.png" alt="image-20220311104903556" style="zoom:95%;" />

<p>可以看到，UE 传输速率的对数被转换为三个不同的度量。接下来分析这三个指标，分别找出它们与服务的<strong>带宽</strong>、<strong>延迟</strong>和<strong>丢包率</strong>的 QoS 要求的关系</p>
<hr>
<p>在DTF中，对于UE <code>n</code>的特定业务流，可以选择 LTE 子信道或 WiFi 信道进行数据传输。当采用LTE子信道时，令 <code>Hn</code> 为流 <code>n</code> 的子流选择的LTE子信道的集合，<code>Hn</code> 中的元素个数为流 <code>n</code> 的子流数，记为 <code>γn</code>。此外，设 <code>rh</code> 和 <code>th</code> 分别为子信道 <code>h</code> 上的传输速率和传输延迟，<code>Tn</code> 可以表示为 <code>max h∈H th</code>。显然，如果让每个选定子信道上的传输延迟相同，并使用更多的子信道进行传输，则可以获得最大传输带宽 <code>Bn</code></p>
<p>当选择 WiFI RAT 来数据传输时，使用 LTE 就不够高效了。因为 WiFi 信道的带宽远大于 LTE 子信道的带宽，因此在采用 WiFi 的情况下，通过增加 LTE 子信道只能略微增加系统传输容量</p>
<p>另外，这种LTE+WiFi在一个短DTF中的传输方式会随着动作空间的显着增加而大大增加信道调度决策的复杂度。因此，将通过在 DTF 中仅使用一种 RAT 来显着降低学习算法的复杂性，从而稍微妥协系统性能</p>
<p>另一方面，在多个 DTF 中，可以通过观察网络状态在数据传输过程中轮流采用两种 RAT，以有效利用网络资源</p>
<hr>
<p>一旦选择了传输模式，就获得并固定了 <code>^Tn</code>。假设 xGBS 可以从附近的 MBS 请求数据，该 MBS 具有大内存来存储整个内容目录 [25]。在这种情况下，对于流 <code>n</code>，延迟主要由通道传输延迟和排队延迟组成</p>
<p>然后文章分析了 <code>^Tn /Tn</code> 与包平均时延的关系。图 3 描述了到达 UE 子流在选定的 LTE 子信道上的传输过程，其中定义 <code>t′0</code> 为请求的开始时间，<code>tm</code> 和 <code>t′m (1&lt;m&lt;γn )</code> 分别作为子流 <code>m</code> 的传输时间的开始和结束。令 <code>dm</code> = <code>t_m -t′_m-1</code> 为两个连续子流之间的时间间隔。则两个子流之间的间隔之和由 <code>Dn = ∑dm</code> 表示。因此，很明显，<code>Tn</code> 随着 <code>Dn</code> 的值增加</p>
<p>此外，在分析平均时延和丢包率时，会考虑过去 DTF 的结果，以获得长期的性能优化。在过去的 KDTF 中，将 <code>x_n (k)</code> 定义为第 <code>k</code> 个过去 DTF 中流 <code>n</code> 的数据包数，因此长期平均时延 <code>Tn</code> 为 <code>∑Tn(k) / ∑x_n(k)</code></p>
<p>通过在当前 DTF 中编排两个连续子流之间的时间间隔来获得可用的长期平均时间延迟</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311105658.png" alt="image-20220311105658051" style="zoom:60%;" />

<center>图 3</center>

<p>SARA 的数据传输过程中采用了拥塞控制机制。由于数据包应该在拥塞中排队等待传输，子流的数据包可能会被阻塞甚至丢弃，因为排队延迟超过了阈值时间，用 <code>η</code> 表示。定义在第 <code>k</code> 个过去的 DTF 中，由于排队时间超过 <code>η</code> 而被丢弃的数据包数量为 <code>ρi (k)</code>。可以得到长期丢包率 <code>Ln</code> 为 <code>∑ρn (k ) / ∑x_n (k ) </code>，用 <code>Pn = 1 - Ln</code> 来表示数据包传输的成功率</p>
<hr>
<p>用 <code>Bn</code>、<code>Tn</code> 和 <code>Pn</code> 表示流 <code>n</code> 向 xGBS 发送信号的带宽、包平均时延和丢包率的 QoS 要求。为了保证流的 QoS 要求，使用一个阶跃函数：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311110418.png" alt="image-20220311110418359" style="zoom:90%;" />

<p>在评估函数设计中，其中 <code>ε</code> 接近 0+，令 <code>B∗n = ε(Bn −Bn th) ·Bn</code>、<code>T ∗n = ε(Tn th −Tn ) ·^Tn /Tn</code>、<code>P ∗n = ε (Pn -Pn th) ·(1 -Ln )</code>。由此，RAP 的评估函数定义为</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311110624.png" alt="image-20220311110623994" style="zoom:90%;" />

<p>这里 <code>wB</code> 、 <code>wT</code> 和 <code>wP</code> 作为权重系数参与进来，以优化期望的折扣奖励的长期总和，为各个 QoS 指标赋予指定的权重。设置权重系数的方法是最大化偏好度量与其他度量之间的权重区别，这样可以粗略地引导算法向权重系数较大的 QoS 度量方向发展。如果去除权重系数（或让 wB = wT = wP ），SARA 的策略输出将朝着最大化系统平均吞吐量的方向改进。通过在 RAP 中使用评估函数 (5)，在基本 QoS 要求约束的情况下动态协调流之间的资源分配策略是可行的</p>
<p>&nbsp;</p>
<h2 id="Part5：SARA-的多智能体强化学习"><a href="#Part5：SARA-的多智能体强化学习" class="headerlink" title="Part5：SARA 的多智能体强化学习"></a>Part5：SARA 的多智能体强化学习</h2><p>给定网络状态 <code>s</code> 和评估函数 <code>r(s, a)</code>，采用强化学习 (RL) 来解决 DTF 中的最优多 RAT 访问问题。由于获得网络状态之间的转移概率 p(s,a) 并不容易，因此采用Model-free Q-Learning 算法来获得其适当性 [26]</p>
<p>将RSP 和 RAP 在多代理系统 (MAS) 下建模，该系统被定义为在同一环境中观察和行动的<strong>代理集合</strong>。在此模型中，为给定流量做出决策会考虑同一 DTF 中其他流量的决策。在 MAS 中，可以观察智能体之前的动作和当前状态，以及每个智能体选择动作后的即时奖励。 MAS 中多个子流的多 RAT 访问决策过程可以建模为一个 n-agent 随机博弈 G[13]，其定义为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">一个n-agent的随机博弈 G 为 &lt;S, A1,···, A n , r 1,···, rn , p ＞，其中S是状态空间，Ai是智能体i的动作空间(i = 1, ···, n )，ri : S ×A1 ×···×An →R 是智能体i的评价函数，p : S ×A1 ×···×An →(S) 是转移概率，其中(S)是状态空间S的一组概率分布</span><br></pre></td></tr></table></figure>

<p>基于提出的 n-agent 随机博弈 G，在 HDF 中，RSP和RAP中的agent之间分别存在<strong>同时博弈</strong>和<strong>顺序博弈</strong>。基于 SMDP 模型，采用 <strong>Nash Q-Learning 算法</strong>、<strong>Policy&amp;Value MCTS 算法（P&amp;V-MCTS）</strong>[11]、<strong>Q-Learning</strong> 算法的变体，分别解决这两个博弈</p>
<h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q-Learning"></a>Q-Learning</h3><p>Q-learning 算法使用 <code>&lt;s, a, r, s&#39;&gt;</code> 形式的转换经验来改进最优状态-动作价值函数的估计 <code>^Q</code>。当采用策略集 <code>π</code> 时，Q 值被定义为状态 <code>s</code> 的预期长期折扣奖励。估计 <code>^Q</code> 更新为：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311134521.png" alt="image-20220311134521060" style="zoom:90%;" />

<p>其中 <code>β ∈[0, 1]</code> 是折扣因子，<code>R</code> 是智能体采取动作 <code>a</code> 时收到的即时奖励，<code>α</code> 是学习率 (0 &lt; α &lt; 1)。在 [27] 中已经证明，如果学习率以适当的速率衰减，<code>^Q(s,a)</code> 最终会收敛到 <code>^Q∗(s,a)</code>。在 Q-Learning 算法的目标是通过迭代找到最优策略 <code>π∗(s) = argmaxa∈A (s) Q(s, a), ∀s, π</code></p>
<h3 id="Nash-Q-Learning-Algorithm-for-RSP"><a href="#Nash-Q-Learning-Algorithm-for-RSP" class="headerlink" title="Nash Q-Learning Algorithm for RSP"></a>Nash Q-Learning Algorithm for RSP</h3><p>在 Nash Q-Learning 算法中，同一决策回合中的智能体尝试从任意猜测开始学习它们的均衡 Q 值。为此，一个智能体需要维护其他智能体的 Q 值，这些值用于通过在每个状态下对其他智能体的动作采取最佳响应动作来更新自己的 Q 值，最终达到<strong>纳什均衡（NE）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在随机博弈中的纳什均衡点定义为：N个策略的元组(π1∗,···, πN∗)，使得对于所有s∈S, πn∈n 和 n=1,···,N,都有 vi(s, π1∗ ,···, π N∗) &gt; vn(s,π1∗,···,π(n-1)∗,πn,π(n+1)∗,···,πN∗), 其中πn是代理n可用的策略集</span><br></pre></td></tr></table></figure>

<p>对于 n-agent 系统，任何 agent 的 Q 函数要变为 <code>Q(s,a1, ···,an)</code>，而不只是 <code>Q(s,a)</code>。将 Nash Q 值定义为当所有代理遵循指定的 纳什均衡策略时的折扣奖励的预期总和：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">智能体n的纳什Q函数定义为(s,a1,···,aN)，当所有智能体遵循联合均衡策略时，智能体n的当前奖励加上其未来奖励的总和，即：Qn∗(s,a1,···,aN) = ri (s,a1,···,aN) + β ∑ p(s′|s,a1,···,aN)*vn (s′,π1∗,···,πN∗)，</span><br><span class="line">其中(π1∗,···, πN∗)是联合纳什均衡策略，rn(s,a1,···,aN)是在联合动作(a1,···,aN)下，状态s中智能体i的单周期奖励，vn(s′,π1∗,···,πN∗)是代理n遵循均衡策略下，从状态s开始无限期的总折扣奖励</span><br></pre></td></tr></table></figure>

<p>文章中，RSP 的过程仅限于静态策略。在 DTF 中，策略和代理的数量是有限的。 Fink (1964) 证明，n 个玩家的随机博弈过程的平稳策略中至少存在一个纳什均衡点[13]</p>
<p>为了模拟真实场景，首先随机初始化网络状态，代理的 Q 值首先设置为零。在状态 <code>s</code>，网络随机选择动作集 <code>(a1, a 2, ..., aγn )</code>，其中 <code>γn</code> 是 UE <code>n</code> 的子流数。当网络状态变为 <code>s&#39;</code> 时，根据纳什Q函数更新UE <code>n</code> 的子流Q值。直到达到 <code>γn</code> 个代理之间的纳什均衡，并向每个代理输出一组可行的 RAT/通道选择策略后，学习过程结束，然后网络为下一个 UE 执行另一轮学习过程。</p>
<p>下面算法 1 中详细阐述了 RSP 的 Nash Q-Learning：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311141515.png" alt="image-20220311141514997" style="zoom:70%;" />

<center>算法 1</center>



<h3 id="Policy-amp-Value-MCTS-Algorithm-for-RAP"><a href="#Policy-amp-Value-MCTS-Algorithm-for-RAP" class="headerlink" title="Policy&amp;Value MCTS Algorithm for RAP"></a>Policy&amp;Value MCTS Algorithm for RAP</h3><p>在 RAP 中，采用 P&amp;V-MCTS 算法解决了多个智能体之间的顺序博弈。每个智能体采取的行动是 RSP 中 Nash Q-Learning 算法输出的可行策略 <code>∏_I_n ∈N</code> 的子集。 P&amp;V-MCTS 在 MCTS 算法中结合了策略和价值网络。对于特定的 UE，策略网络用于采样动作，价值网络用于评估选择的策略。假设在 Monte-Carlo 搜索树中，每个节点 s 包含树的所有动作的边 <code>(s, a)</code>，每个边存储一组统计参数为 <code>&#123;r(s, a), N(s, a), Q(s, a)&#125;</code>，其中 <code>r(s, a)</code> 是即时奖励，<code>N (s, a)</code> 是访问次数，<code>Q(s, a)</code> 是来自价值网络的动作价值，由 Q-learning 算法更新</p>
<p>具体来说，P&amp;V-MCTS 包括三个策略步骤，即策略选择、模拟和反向传播，如图 4 所示：</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311142248.png" alt="image-20220311142248482" style="zoom:60%;" />

<center>图 4</center>

<h4 id="Selection"><a href="#Selection" class="headerlink" title="Selection"></a>Selection</h4><p>在每个步骤中，对于 UE，根据动作选择策略： <code>a = argmaxa (Q(s, a) + u(s, a))</code> 选择一组 LTE 子信道或 WiFi 信道，通过使用变体树（UCT）算法中的上置信区间[28]，其中</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311142838.png" alt="image-20220311142838566" style="zoom:95%;" />

<p>是鼓励探索和开发的奖励，其中 <code>c</code> 决定了探索的程度，<code>P(s,a)</code> 是先验概率</p>
<p>在策略网络中，让 WiFi 信道以高先验概率被选择，而其他 LTE 子信道以相等概率被选择。 UCT 算法利用上置信键 (UCB) 算法在树中的每个点智能地分配搜索资源。这种搜索策略最初偏爱具有高 Q 值和低访问次数的动作，但会逐渐偏爱具有高动作值的动作</p>
<h4 id="Simulation"><a href="#Simulation" class="headerlink" title="Simulation"></a>Simulation</h4><p>在 RAP 的顺序博弈中，代理根据 DTF 中的到达时间顺序做出决策。模拟从搜索树的根（第一个代理）开始，到叶节点（最后一个代理）结束。将模拟定义为尝试在估计的Q值收敛到最大Q值 或 时间到达之前搜索最佳策略的试验</p>
<h4 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h4><p>当模拟到达叶节点时，会启动一个单独的反向传递来更新遍历边的统计参数，其中每个节点的 <code>Q(s, a)</code> 由 Q-learning 算法更新，每个访问节点的访问次数为增加 1</p>
<p>搜索过程可以随时终止并输出一组当前的最佳策略，以满足[11]中的实时要求。换言之，学习时间或试验次数应动态调整，从而避免违反 UE 的 QoS 要求</p>
<p>算法 2 描述了 RAP 的 P&amp;V-MCTS 算法，旨在为每个交通流找到理想的资源分配策略。正如算法 2 中总结的那样，每个节点上的 Q 值和访问次数首先被初始化为零。网络状态是随机初始化的。代理 <code>n</code> 根据 UCT 算法选择一个动作。当网络状态变为 <code>s&#39;</code> 时，代理 <code>n</code> 的 Q 值根据初步 Q 函数更新，访问节点的访问次数增加 1。直到算法收敛或时间到达后，学习过程结束，然后将相应的资源分配策略输出给每个代理</p>
<img src="https://my-picture-1311448338.file.myqcloud.com/img/20220311143323.png" alt="image-20220311143323121" style="zoom:75%;" />

<center>算法 2</center>

<p>&nbsp;</p>
<p>&nbsp;</p>
<p>文章后面分析了整个系统的复杂度和性能，<strong>略</strong></p>

      </div>
      
      
      
    </div>
    

    
    
    


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E5%AF%BC%E5%90%91%E5%8F%8A%E7%8E%B0%E6%9C%89%E7%A0%94%E7%A9%B6"><span class="nav-text">问题导向及现有研究</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A-RAT-%E7%9A%84%E8%83%8C%E6%99%AF"><span class="nav-text">多 RAT 的背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A-RAT-%E7%9A%84%E9%97%AE%E9%A2%98-%E4%B8%8E-AI%E6%9C%BA%E9%81%87"><span class="nav-text">多 RAT 的问题 与 AI机遇</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E7%AB%A0%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9"><span class="nav-text">文章工作内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6"><span class="nav-text">相关研究</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%88%E6%9D%83%E5%92%8C%E9%9D%9E%E6%8E%88%E6%9D%83%E9%A2%91%E6%AE%B5%E7%9A%84%E7%BB%84%E5%90%88%E6%9C%BA%E5%88%B6"><span class="nav-text">授权和非授权频段的组合机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%9A%E8%BF%87-WiFi-%E7%9A%84-RAT-%E8%BF%9B%E8%A1%8C%E6%B5%81%E9%87%8F%E5%8D%B8%E8%BD%BD"><span class="nav-text">通过 WiFi 的 RAT 进行流量卸载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%8D%8A%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B"><span class="nav-text">强化学习和半马尔可夫决策过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-2%EF%BC%9A-LTE-WIFI-%E8%81%9A%E5%90%88%E2%80%94%E2%80%94%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B"><span class="nav-text">Part 2： LTE-WIFI 聚合——系统模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF%E6%8F%8F%E8%BF%B0"><span class="nav-text">场景描述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BF%A1%E9%81%93%E6%8E%A5%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="nav-text">信道接入模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part3%EF%BC%9A%E9%97%AE%E9%A2%98%E5%BB%BA%E6%A8%A1%E4%B8%8E%E5%88%86%E6%9E%90"><span class="nav-text">Part3：问题建模与分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%90%E8%90%A5%E5%95%86%E8%A7%92%E5%BA%A6"><span class="nav-text">运营商角度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UE%E8%A7%92%E5%BA%A6"><span class="nav-text">UE角度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part4%EF%BC%9A%E5%A4%9ARAT%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E7%9A%84%E5%8D%8A%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B"><span class="nav-text">Part4：多RAT访问控制的半马尔可夫决策过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-SMDP-%E7%9A%84%E5%88%86%E5%B1%82%E5%86%B3%E7%AD%96%E6%A1%86%E6%9E%B6"><span class="nav-text">基于 SMDP 的分层决策框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RAT%E4%BF%A1%E9%81%93%E9%80%89%E6%8B%A9%E8%BF%87%E7%A8%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0"><span class="nav-text">RAT信道选择过程的评估函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E7%9A%84%E8%BF%87%E7%A8%8B%E7%9A%84%E8%AF%84%E4%BC%B0%E5%87%BD%E6%95%B0"><span class="nav-text">资源分配的过程的评估函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part5%EF%BC%9ASARA-%E7%9A%84%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="nav-text">Part5：SARA 的多智能体强化学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Q-Learning"><span class="nav-text">Q-Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nash-Q-Learning-Algorithm-for-RSP"><span class="nav-text">Nash Q-Learning Algorithm for RSP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Policy-amp-Value-MCTS-Algorithm-for-RAP"><span class="nav-text">Policy&amp;Value MCTS Algorithm for RAP</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Selection"><span class="nav-text">Selection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Simulation"><span class="nav-text">Simulation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Backpropagation"><span class="nav-text">Backpropagation</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Lrk612"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Lrk612</p>
  <div class="site-description" itemprop="description">Lrk's blog</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">51</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.google.com/" title="https:&#x2F;&#x2F;www.google.com" rel="noopener" target="_blank">Google</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://arxiv.org/" title="https:&#x2F;&#x2F;arxiv.org&#x2F;" rel="noopener" target="_blank">arXiv</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://ieeexplore.ieee.org/Xplore/home.jsp" title="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;Xplore&#x2F;home.jsp" rel="noopener" target="_blank">IEEE Xplore</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <!-- 访问量 -->

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 


<!-- 版权 -->
<div class="copyright">
  
  &copy; 2021-12-1 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lrk612</span>
</div>

<!-- ICP备案 -->
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP备案 </a>
      <img src="https://my-picture-1311448338.file.myqcloud.com/img/20211209170739.png" style="display: inline-block;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=2021035798" rel="noopener" target="_blank">豫ICP备2021035798号 </a>
  </div>

<!-- 不知道是什么 -->
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'fH6OdGBcCG8D6jC8NeeJlX9b-gzGzoHsz',
      appKey     : '1UoIb6vszMw6wl0n7kreb4Xz',
      placeholder: "Just go go ^_^",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
    var infoEle = document.querySelector('#comments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0){
      infoEle.childNodes.forEach(function(item) {
        item.parentNode.removeChild(item);
      });
    }
  }, window.Valine);
});
</script>

</body>
</html>
