<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sharp-rookie.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

<script> 
   (function(){
          if(''){
              if (prompt('请输入文章密码') !== ''){
                  alert('密码错误！');
                  history.back();
              }
          }
      })();
  </script>
  <meta name="description" content="文章提出了一个含两种时间尺度的 RAN 切片机制来优化 URLLC 和 eMBB 服务的性能  大时间尺度上，SDN控制器根据eMBB和URLLC业务的需求为gNodeB分配无线资源 短时间尺度上，每个 gNodeB 将其可用资源分配给其 UE ，并在需要时从相邻 gNodeB 请求额外资源  文章证明了此问题是个 NP-Hard 问题。然后把每个时间尺度建模为马尔可夫决策过程（MDP），其中大时">
<meta property="og:type" content="article">
<meta property="og:title" content="一种利用单智能体和多智能体RL的无线接入网RB资源动态分配模型">
<meta property="og:url" content="https://sharp-rookie.github.io/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="最忆是江南">
<meta property="og:description" content="文章提出了一个含两种时间尺度的 RAN 切片机制来优化 URLLC 和 eMBB 服务的性能  大时间尺度上，SDN控制器根据eMBB和URLLC业务的需求为gNodeB分配无线资源 短时间尺度上，每个 gNodeB 将其可用资源分配给其 UE ，并在需要时从相邻 gNodeB 请求额外资源  文章证明了此问题是个 NP-Hard 问题。然后把每个时间尺度建模为马尔可夫决策过程（MDP），其中大时">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312162931.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312162931.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312222009.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312222138.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312224919.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312225249.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312225321.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312153530.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312153547.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312155705.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312155730.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312162847.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312200317.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312201130.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312201748.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312202548.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312204028.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312204906.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312221112.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312221643.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312205910.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312210909.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312210927.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312211613.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312212049.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312212213.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312212435.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312212612.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312220424.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312220606.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312220723.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312220804.png">
<meta property="article:published_time" content="2022-03-12T15:04:22.650Z">
<meta property="article:modified_time" content="2022-04-25T03:39:28.355Z">
<meta property="article:author" content="Lrk612">
<meta property="article:tag" content="5G">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Reinforcement Learning">
<meta property="article:tag" content="Mutli-Agent RL">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Resourse Management">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-picture-1311448338.file.myqcloud.com/img/20220312162931.png">

<link rel="canonical" href="https://sharp-rookie.github.io/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>一种利用单智能体和多智能体RL的无线接入网RB资源动态分配模型 | 最忆是江南</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
        <a target="_blank" rel="noopener" href="https://github.com/Sharp-rookie" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">最忆是江南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Love actually is all around</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th-list fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-papers">

    <a href="/papers/" rel="section"><i class="fa fa-book fa-fw"></i>论文阅读</a>

  </li>
        <li class="menu-item menu-item-friendlink">

    <a href="/friendlink/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sharp-rookie.github.io/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Lrk612">
      <meta itemprop="description" content="Lrk's blog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最忆是江南">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          一种利用单智能体和多智能体RL的无线接入网RB资源动态分配模型
        </h1>

        <div class="post-meta">
         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-03-12 23:04:22" itemprop="dateCreated datePublished" datetime="2022-03-12T23:04:22+08:00">2022-03-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
            </span>

          
            <span id="/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/" class="post-meta-item leancloud_visitors" data-flag-title="一种利用单智能体和多智能体RL的无线接入网RB资源动态分配模型" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>文章提出了一个含<strong>两种时间尺度</strong>的 RAN 切片机制来优化 <strong>URLLC</strong> 和 <strong>eMBB</strong> 服务的性能</p>
<ul>
<li>大时间尺度上，SDN控制器根据eMBB和URLLC业务的需求为gNodeB分配无线资源</li>
<li>短时间尺度上，每个 gNodeB 将其可用资源分配给其 UE ，并在需要时从相邻 gNodeB 请求额外资源</li>
</ul>
<p>文章证明了此问题是个 NP-Hard 问题。然后把每个时间尺度建模为马尔可夫决策过程（MDP），其中大时间尺度被建模为<strong>单个代理 MDP</strong>，而较短时间尺度被建模为<strong>多代理 MDP</strong></p>
<p>文章利用<strong>指数权重算法 (EXP3)</strong> 来解决大时间尺度 MDP 的单智能体 MDP，并利用<strong>多智能体 Deep Q-Learning 算法</strong>来求解多智能体 MDP，即短时间尺度的资源分配</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312162931.png" alt="image-20220312162931068" style="zoom:60%;" /></p>
<p><strong>原文</strong></p>
<p><a target="_blank" rel="noopener" href="https://lrk612.com/resources/Dynamic%20SDN-based%20Radio%20Access%20Network%20Slicing%20with%20Deep%20Reinforcement%20Learning%20for%20URLLC%20and%20eMBB%20Services.pdf">Dynamic SDN-based Radio Access Network Slicing with Deep Reinforcement Learning for URLLC and eMBB Services</a></p>
<span id="more"></span>
<p>&nbsp;</p>
<h2 id="问题导向及现有研究"><a href="#问题导向及现有研究" class="headerlink" title="问题导向及现有研究"></a>问题导向及现有研究</h2><h3 id="NS-amp-SDN-amp-问题背景"><a href="#NS-amp-SDN-amp-问题背景" class="headerlink" title="NS &amp; SDN &amp; 问题背景"></a>NS &amp; SDN &amp; 问题背景</h3><p>5G支持的异构业务主要分为增强型移动宽带（eMBB）、超可靠低时延通信（URLLC）和海量机器类通信（mMTC）服务 [1]：</p>
<ul>
<li>eMBB 服务面向需要高数据速率的应用，例如高清 (HD) 视频或大规模视频流</li>
<li>URLLC 服务适用于低延迟和高可靠性的应用，例如自动驾驶或机器人手术</li>
<li>mMTC 服务提供与大量设备的连接，例如物联网 (IoT) 网络中的大规模访问 [2]、[3]，其特点是数据量小、流量零星</li>
</ul>
<p>为了支持这三种 5G 服务，同时尊重它们对通用无线网络基础设施的异构和不同要求，无线接入网切片被视为下一代蜂窝网络的关键使能技术。<strong>网络切片 (NS)</strong> 提供了构建多个独立逻辑网络（称为网络切片）的能力，每个网络切片都适应特定服务的需求 [5]。因此，每个 RAN 切片都可以定制并专用于支持具有独特特征和要求的特定服务。网络运营商可以利用<strong>软件定义网络 (SDN)</strong> 提供的网络可编程性来动态管理为 RAN 切片提供的无线电资源</p>
<p>与云 RAN (C-RAN) 架构不同，在部署多接入边缘计算 (MEC) 环境时，维护服务可用性和利用 MEC 资源方面有着重大挑战 [7]，SDN 可以被认为是重要的 fog RAN (F-RAN) 架构中的 5G RAN 使能器。具体而言，将 SDN 与 F-RAN 共同部署可提高利用其网络全局视野开发无线电资源的能力 [8]。在这项工作中考虑的无线电资源是资源块（RB），它是可以分配给 UE 的最小资源元素，它由频带和时隙对标识。每个 gNodeB 应该有足够的来自共享无线电 RB 池的 RB 来满足其 UE 的需求。在 RAN 切片场景中，SDN 可用于为每个 gNodeB 中的每个 RAN 切片分配适当的 RB，具体取决于无线电资源的可用性和相应 gNodeB 的 UE 所需的服务，这里的难点是<strong>如何实现为每个基站设计最优RBs分配方案以满足其不同切片中的 UE 的QoS要求</strong></p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312162931.png" alt="image-20220312162931068" style="zoom:70%;" /></p>
<center>图 1</center>

<h3 id="相关工作调研"><a href="#相关工作调研" class="headerlink" title="相关工作调研"></a>相关工作调研</h3><p>为了解决这个问题，近年来提出了各种各样的算法和方案[9]-[18]，主要提出集中式资源分配解决方案或多级资源分配解决方案</p>
<ul>
<li><p>在<strong>集中式</strong>解决方案中，无线资源分配决策仅依赖于中央实体（例如SDN控制器），这增加了gNodeB与中央实体之间频繁通信导致的网络信令开销，尤其是当后者具有执行不同 gNodeB 的资源分配时。因此，预计将无线电资源分配给 UE 的操作将在较大的时间范围内执行</p>
</li>
<li><p>在<strong>多级资源分配</strong>解决方案方法中，SDN控制器在上层将无线电资源分配给RAN切片或gNodeB。后者负责在较低级别并基于SDN控制器预先分配的资源，为 UE 分配无线电资源。虽然多级资源分配方案可以有效地为 UE 分配资源块，但是当SDN控制器预先分配的资源不足以处理所需的业务时，低级分配操作可能会失败，因为它必须等待下一个资源预留更新或立即向 SDN 控制器请求更多资源，这会显着降低网络运营商预期提供的 QoS</p>
</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>文章</th>
<th>主要思路</th>
<th>不足</th>
</tr>
</thead>
<tbody>
<tr>
<td>[9]</td>
<td>使用两种机器学习方法提出了 RAN 切片框架：<br/>1. 用LSTM预测在较长时间内分配给切片的资源量<br/>2. 用多智能体 RL 算法：异步 actor-critic agent (A3C)，为RAN切片做在线资源调度</td>
<td>仅考虑了eMBB类型的UE，并且没有考虑对单个UE的切片</td>
</tr>
<tr>
<td>[10]</td>
<td>控制器考虑每个切片的最小资源需求来在每个基站为 URLLC 和 eMBB 切片预留资源<br/>然后根据预留的资源用DRL来动态更新分配，以满足用户 QoS 满意度和资源利用效用</td>
<td></td>
</tr>
<tr>
<td>[11]</td>
<td>通过调整预留给各个 RAN 切片的资源来提高用户 QoS 满意度和资源利用效用<br/>利用 Dueling DQN 算法解决切片资源供应问题</td>
<td>不允许使用超出控制器预留的资源，所以预留资源不够时，切片必须等下次更新时才能继续工作</td>
</tr>
<tr>
<td>[12]</td>
<td>提出了一种用于两层异构无线网络的动态无线电资源切片方案，以确定切片的最佳带宽切片比率。一种替代的凹搜索算法被设计来解决最大网络效用优化问题</td>
<td>1. 虽然提出的方案满足机器类型和数据切片的 QoS 要求，但它不能支持需要低得多的延迟的 URLLC 切片<br/>2. 每个切片的资源预计只会在较大的时间范围内更新</td>
</tr>
<tr>
<td>[13]</td>
<td>设计了一个基于 SDN 的两级无线电资源分配框架，以改进不同时间尺度上的 RAN 切片<br/>1. 大时间尺度上，SDN控制器将RB分配给gNodeB<br/>2. 小时间尺度上，每个gNodeB将预分配的RB调度给eMBB和URLLC用户<br/>当预留的RBs不足时，每个gNB可以向其他gNB借用RBs</td>
<td>没有明确描述基站之间共享RB的交互</td>
</tr>
<tr>
<td>[14]</td>
<td>兼顾了eMBB、URLLC 和 mMTC 切片用户的要求，将用户关联和资源分配问题建模为最大效用优化问题，并用分层分解方法将优化问题分解为两个子问题：<br/>1. 基站-切片用户关联子问题，通过多对一匹配博弈求解<br/>2. 动态资源分配子问题，采用遗传算法求解</td>
<td></td>
</tr>
<tr>
<td>[15]</td>
<td>提出了一个动态框架来为两种类型的车载网络服务分配无线电资源：延迟敏感、延迟容忍<br/>把无线电资源分配问题与计算资源分配问题共同制定为优化问题<br/>使用两层约束 RL 算法来求解，SDN 控制器用RL决策为所有基站的切片分配资源</td>
<td></td>
</tr>
<tr>
<td>[16]</td>
<td>多个服务提供商通过竞争以协调通道访问机会，从而为其移动用户提供对虚拟计算和通信切片的访问<br/>文章将此类资源分配问题建模为<strong>非合作随机博弈</strong>，并利用基于双深度 Q 网络的深度学习方法来近似最优分配策略</td>
<td></td>
</tr>
<tr>
<td>[17]</td>
<td>提出了一种两步式 RAN 切片框架来提高带宽利用率：<br/>1. 选择一组同时满足 QoS 的用户<br/>2. 每个被选用户通过特定基站与一个切片相关联，并且分配基站部分带宽给它</td>
<td></td>
</tr>
<tr>
<td>[18]</td>
<td>把根据切片需求来分配无线资源的问题建模为受正交约束（即服务隔离）、延迟相关约束和最小速率约束的总速率最大化问题<br/>先用非线性 AMC 可实现吞吐量的近似值来放松 AMC 的数学难处理性<br/>然后通过使用问题的惩罚性重构将二元约束放松为框约束<br/>最后又提出一种启发式算法求解问题的思路，比上面方法复杂度更低</td>
</tr>
</tbody>
</table>
</div>
<h3 id="文章工作内容"><a href="#文章工作内容" class="headerlink" title="文章工作内容"></a>文章工作内容</h3><p>文章通过提出两级 RB 分配机制来填补这两个空白。在第一层和大时间尺度上，SDN控制器根据gNodeB的要求从公共无线电RB池中为每个gNodeB分配一定数量的RB。在第二层，每个 gNodeB 在短时间内将预分配的 RB 调度给其关联的UE，以满足他们在数据速率和延迟方面的 QoS 要求。这种机制避免了由于无线网络流量的突然和潜在的意外波动而导致 gNodeB 和 SDN 控制器之间的频繁通信。为了进一步减少 gNodeB 和 SDN 控制器之间的通信，gNodeB 可以在其预分配的 RB 不足时向其他相邻的 gNodeB 请求额外的 RB，从而可以立即响应 UE 的要求</p>
<p>在这项工作中，考虑了两种类型的切片，每种切片专用于单个 5G 服务，即 eMBB 服务和 URLLC 服务。然后，我们将两级 RB 分配问题表述为一个优化问题，其目标是最大化 eMBB 和 URLLC  UE 的总可实现数据速率。这一目标的实现必须满足 URLLC 服务的超低延迟要求以及 eMBB 服务的最低数据速率要求。解决这一优化问题的建议机制将：</p>
<ol>
<li>减少gNodeB和SDN控制器之间的信令开销</li>
<li>快速为不同切片提供所需的RB以满足相应 UE 请求的服务</li>
</ol>
<p>文章工作的新颖之处在于两个主要部分：</p>
<ol>
<li>使用整数规划定义了两级无线电RB分配问题，并分析了它的 NP-Hard 情况</li>
<li>提出了一个单智能体多智能体强化学习（SA-MA-RL）框架来解决两级无线电RB分配问题</li>
</ol>
<p>因此，其所提出的基于 RL 的 RAN 切片框架是动态的，因为 RL 算法可以根据不同因素永久调整其 RB 分配策略，这些因素主要包括网络中 UE 的密度、eMBB 和 URLLC 服务的需求，以及无线信道的传输条件。此外，文章提出的 RAN 切片方法在两个时间尺度上执行，以两个级别来分配资源，包括 SDN 控制器级别和 gNodeB 级别</p>
<p>本文的主要内容总结如下：</p>
<ul>
<li>使用数学规划将 eMBB 和 URLLC  UE 的全局 RB 分配建模为非线性二进制程序，并研究其 NP-Hard</li>
<li>由于是 NP-Hard ，获得 RB 分配问题的最优解在计算上的成本过高，因此将每个级别的 RB 分配问题建模为马尔可夫决策过程 (MDP)</li>
<li>为了根据gNodeB 的要求公平地划分RB，我们设计了一种基于单代理RL 的算法来在第一分配级别在gNodeB 之间划分RB</li>
<li>在gNodeB级别，基于SDN控制器预先分配给gNodeB的RBs，提出了一种多智能体深度Q学习（DQL）方法来分配RB给eMBB和URLLC UE ，并在gNodeB之间进行RB共享</li>
<li>根据基准算法评估其提出的机制的性能，并进行广泛的模拟以显示提出的框架的优越性</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2 id="Part-2：-系统模型"><a href="#Part-2：-系统模型" class="headerlink" title="Part 2： 系统模型"></a>Part 2： 系统模型</h2><p>考虑由一组有限的 gNodeB：<code>B = &#123;1,2,...,B&#125;</code> 组成的支持 SDN 的 5G RAN 架构</p>
<p>考虑两种切片，即 URLLC 切片和 eMBB 切片，分别用 <code>su</code> 和 <code>se</code> 表示</p>
<p>频谱资源表示为一个共享的 RB 池，记为 <code>K= &#123;1,2,...,K&#125;</code>，其中每个 RB 代表最小调度单元</p>
<p>终端用户 UE <code>U = &#123;1,2,...,U&#125;</code> 随机分布在整个网络区域，均为 URLLC UE或 eMBB UE。每个 UE：u ∈U 由一个 gNodeB 服务并属于一个切片，即 <code>su</code> 或 <code>se</code>。每个 gNodeB：b ∈B 都有一组关联的 UE ，用 <code>Ub</code> 表示</p>
<p>考虑正交频分多址 (OFDMA) 下行链路 (DL) 场景，其中 RB 被组织为资源网格 [18]。使用 OFDMA，以正交方式调度到 UE 的传输以减少干扰</p>
<hr>
<p>RB 分配过程在两个级别中执行</p>
<p>在第一层，SDN 控制器具有网络的全局视野，在较大的时间范围内将 RB 分配给 gNodeB。文章将此RB分配级别称为SDN分配级别。 SDN 控制器分配给 gNodeB b ∈B 的一组 RB 由 Kb ⊆K 提高</p>
<p>在第二层，RB 分配过程由 gNodeB 执行，将 RB 分配给每个 UE 。文章将此 RB 分配级别称为 gNodeB 分配级别</p>
<p>每个 gNodeB b ∈B 在短时间内从预先分配的 RBs： Kb ⊆K 中为每个相关的 UE 分配一些 RBs，以满足每个 UE在数据速率和延迟方面的 QoS 要求。为了确保由同一 gNodeB b ∈B 服务的 UE 之间的 DL 传输的正交性，每个 RB k ∈ Kb 被<strong>排他地</strong>分配给一个 UE：ub ∈ Ub</p>
<p>用二进制变量 <code>xk_ub</code> 表示 RB：k 是否分配给了 UE ub</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312222009.png" alt="image-20220312222009821" style="zoom:80%;" /></p>
<center>二式表示一个RB必须一次只分配给一个 UE （反应了OFDMA约束）</center>

<hr>
<p>在 5G NR 中，可扩展的 OFDM 技术是一项关键创新。 3GPP 5G NR 第 15 版规范 [19] 指出波形是可扩展的，因为 OFDM 的子载波间隔可以适应信道宽度。间距参数的选择取决于几个因素，包括 5G 业务的要求，例如 URLLC 业务的低延迟和 eMBB 业务的高数据速率。实际上，eMBB 和 URLLC 服务可以通过多路复用两种不同的参数集在同一载波上同时支持，URLLC 服务的子载波间隔更大，eMBB 服务的子载波间隔更小</p>
<p>在文章的方法中，RB分配操作是在考虑给定的时频资源网格模型的情况下执行的。换言之，对于特定的子载波间隔，例如 15 KHz、30 KHz 和 60 KHz，应使用适当的训练模型来执行 RB 分配操作</p>
<p>文章假设 gNodeB 对信道状态信息 [20]、[21] 有（近乎）完美的了解。当衰落随时间缓慢变化并且 UE 的移动性较低时，在真实 5G 网络中，gNodeB 上（接近）完美的信道状态信息的可用性是合理的，因为无线信道不会快速变化，这类似于本文的案例。可以使用例如深度学习算法 [22] 在 5G 网络中准确估计信道状态信息</p>
<p>在第 <code>k</code> 个 RB 上与第 <code>b</code> 个 gNodeB 相关联并属于切片 <code>s ∈&#123;su,se&#125;</code> 的第 <code>ub</code> 个 UE 的可实现数据速率定义如下：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312222138.png" alt="image-20220312222138477" style="zoom:80%;" /></p>
<p>其中 <code>W</code> 表示 RB 的带宽，<code>P_s_ub</code> 是基站 b ∈ B 到 UE ub ∈ Ub 在切片 s ∈ {su,se} 中的传输功率，<code>Gub_k</code> 是基站 b ∈ B 与其关联的 DL 信道增益 UE ub ∈ Ub，<code>σ2</code> 是加性高斯白噪声 (AWGN) 的功率，这里假设所有 RB 的带宽和下行传输功率都相同</p>
<hr>
<p>在第二级资源分配过程中，如果SDN控制器没有为一个gNodeB分配足够的RB，后者可以向其他gNodeB请求额外的RB。当且仅当 <code>∑ ub∈Ub ∑ k∈Kb x_k_ub ≥|Kb|</code>（即预留的RB确实不够用）时，gNodeB b 才可以从其他 gNodeB 请求额外的 RB 并将它们分配给其相关的 UE。这个约束可以定义如下：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312224919.png" alt="image-20220312224919264" style="zoom:80%;" /></p>
<p>其中 k‘ 是从其他基站 b 借来的RB，显然此时 <code>x_k&#39;_ub = 1</code></p>
<hr>
<p>属于切片 <code>s ∈ &#123;su,se&#125;</code> 并与 gNodeB b ∈ B 相关联的UE：ub ∈Ub 的总数据速率定义为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312225249.png" alt="image-20220312225249659" style="zoom:80%;" /></p>
<hr>
<p>为了计算 URLLC 和 eMBB 流量的延迟，假设：</p>
<ol>
<li>每个 gNodeB 数据包的到达过程遵循<strong>泊松分布</strong></li>
<li>数据包的到达间隔时间是独立的并且遵循<strong>指数分布</strong>[23]</li>
</ol>
<p>因此，排队流量模型可以被认为是一个 M/M/1 排队系统。此外，不同切片的数据包长度不同，但在切片 <code>s ∈&#123;su,se&#125;</code> 中它们是相似的。下式是通过应用<strong>利特尔定律</strong>来计算得到的时延。属于切片 <code>s ∈ &#123;su,se&#125;</code> 且与 b ∈B 相关联的 UE 数据包 <code>ub</code> 经历的平均延迟 <code>d_s_ub</code> ，其中 <code>λ_s_ub</code> 是 <code>ub ∈Ub</code> 且属于切片 <code>s ∈ &#123;su,se&#125;</code> 的数据包到达率：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312225321.png" alt="image-20220312225321214" style="zoom:90%;" /></p>
<p>文章选择 M/M/1 排队系统，是因为它广泛用于表征无线通信系统，特别是在 RAN 切片方法 [15]、[24]、[25] 中</p>
<p>然而，在一些实际场景中，流量会变得突发，因此 M/M/1 假设（即每个 gNodeB 的数据包到达过程遵循泊松分布）可能太过乐观。在这种情况下，gNodeB 不能被视为 M/M/1 系统，队列不能被建模为连续时间马尔可夫过程。在这种情况下，流量突发时，排队系统可以建模为离散时间马尔可夫过程[26]，[27]。如[28]所示，许多连续时间马尔可夫过程可以通过仅观察状态转换转换为离散时间马尔可夫过程。由于 M/M/1 排队假设可以看作是一个连续时间的马尔可夫过程，所以在这项工作中获得的分析和结果对于大多数无法应用泊松分布的场景都是有效的。注意，在不同的排队假设下，数学分析可能会有所不同且更加复杂。简单起见，这里只假设了 M/M/1 的情况</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2 id="Part3：RB分配问题建模-amp-NP-Hard分析"><a href="#Part3：RB分配问题建模-amp-NP-Hard分析" class="headerlink" title="Part3：RB分配问题建模 &amp; NP-Hard分析"></a>Part3：RB分配问题建模 &amp; NP-Hard分析</h2><h3 id="场景建模"><a href="#场景建模" class="headerlink" title="场景建模"></a>场景建模</h3><p>RAN中RB分配的主要问题是如何为URLLC和eMBB的UE推导RB的两级最优分配，以满足其在数据速率和延迟方面的QoS要求。为此，全局RB分配优化问题表述如下：</p>
<p>优化目标是最大化URLLC和eMBB的UE总数据速率：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312153530.png" alt="image-20220312153530543" style="zoom:75%;" /></p>
<p>约束条件：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312153547.png" alt="image-20220312153547076" style="zoom:75%;" /></p>
<p>其中，<code>x_k_ub</code> 表示用户 ub 是否分配得到第 <code>k</code> 个RB（二进制变量），每个约束含义为：</p>
<ul>
<li>(7b) 表示每个UE分配的最大RB数量不超过 <code>Kmax</code>，从而保证分配的公平性</li>
<li>(7c) 表示每个RB一次只分配给一个UE（OFDMA的约束）</li>
<li>(7d) 表示gNB只有当预留RB都用完时，可以向其他gNB借额外RBs</li>
<li>(7e) 表示eMBB类型UE的速率必须大于其最低下限</li>
<li>(7f) 表示URLLC类型UE的时延必须小于其最高上限</li>
<li>(7g) 列出了所有优化变量</li>
</ul>
<p>主要是由于优化变量的二进制性质和方程式中定义的 UE 所经历的延迟的非线性，RB分配问题是一个非线性二元规划问题，因此难以求解。下面分析它的 NP-Hard 情况</p>
<p>&nbsp;</p>
<h3 id="NP-Hard-分析"><a href="#NP-Hard-分析" class="headerlink" title="NP-Hard 分析"></a>NP-Hard 分析</h3><p>文章用 P 表示上述优化问题。为了证明 P 是 NP-hard，文章将NP-hard的 0-1 背包问题  [29] 简化为 P 的一个实例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0-1背包问题：</span><br><span class="line">给定一组 N 件物品，每件物品都有它的利润 pi 和重量 wi，以及一个容量为 C 的背包</span><br><span class="line">每个物品可以放入或不放入背包（1或0）</span><br><span class="line">目标是找到一个子集 N′⊆N 使得物品的总价值 ∑ni∈N′ pi 最大化，并且所选物品的总重量小于或等于背包容量，即 (∑ni∈N′ wi)≤C</span><br></pre></td></tr></table></figure>
<p>证明问题 P 为 NP-Hard：</p>
<p>如果 P 的受限情况下就是NP-Hard问题，那么在一般情况下就也是 NP 难的，所以考虑受限情况：</p>
<ul>
<li>简化为只有一个 gNodeB，用 <code>b</code> 表示，其相关的UE设置为 <code>ub</code></li>
<li>简化为只有eMBB 切片</li>
<li>假设SDN控制器Kb为 <code>b</code> 预分配的RB是已知的，即：第一级RB分配过程已经由SDN控制器执行过了</li>
</ul>
<p>在这种情况下，P 等效于：</p>
<p>优化目标最大化eMBB的UE总数据速率：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312155705.png" alt="image-20220312155705408" style="zoom:80%;" /></p>
<p>约束条件：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312155730.png" alt="image-20220312155730468" style="zoom:75%;" /></p>
<p>其中，每个约束含义为：</p>
<ul>
<li>(8b) 表示每个UE分配的最大RB数量不超过 <code>Kmax</code>，从而保证分配的公平性</li>
<li>(8c) 表示每个 RB 一次仅分配给一个UE</li>
<li>(8d) 表示eMBB类型UE的速率必须大于其最低下限</li>
<li>(8e) 列出了所有优化变量</li>
</ul>
<p>为了将 0-1 背包问题映射为此优化问题， 令</p>
<ol>
<li>物品数 N 对应 eMBB 的 UE 数量</li>
<li>每个物品的利润 <code>pi</code> 对应 eMBB 每个UE的数据速率 <code>ub</code></li>
<li>每个物品的重量 wi 对应为 eMBB 每个UE分配的 RB数</li>
<li>背包容量 C 对应预留给 gNB <code>b</code> 的 RB 数量</li>
</ol>
<p>由此，问题 P 显然简化为了背包问题。考虑到背包容量有限，分配给所有 eMBB 的UE的 RB 数量不超过 |Kb|</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2 id="Part4：基于-Single-Agent-amp-Mutli-Agent-RL-的资源切片"><a href="#Part4：基于-Single-Agent-amp-Mutli-Agent-RL-的资源切片" class="headerlink" title="Part4：基于 Single-Agent &amp; Mutli-Agent RL 的资源切片"></a>Part4：基于 Single-Agent &amp; Mutli-Agent RL 的资源切片</h2><p>资源分配问题很难在两级过程（即：控制器级和 gNodeB 级）中取得最优解。为了克服这一挑战，文章利用机器学习技术，特别是 RL 来执行 RB 分配任务，因为它能以高效的计算方式解决无线网络资源分配问题[30]</p>
<p>文章提出了一种单智能体-多智能体-强化学习 (SA-MA-RL) 框架来解决两级 RB 分配问题，如图 2 所示</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312162847.png" alt="image-20220312162847141" style="zoom: 80%;" /></p>
<center>图 2</center>

<h3 id="SDN-Level"><a href="#SDN-Level" class="headerlink" title="SDN Level"></a>SDN Level</h3><p>因为在 SDN 分配级别的资源分配不受维数爆炸问题的影响，所以文章选择了经典的 RL 算法：<strong>指数权重算法</strong> (EXP3) 进行探索和利用[31]，SDN控制器扮演 RL agent 的角色，执行将 RB 分配给 gNodeB 的操作</p>
<p>由于状态和动作空间不大，SDN 控制器代理可以在合理的时间内训练学习。EXP3 是一种很合适的算法，因为它不依赖于与 SDN 分配系统的动态性相关的任何假设，这使得它在 RB 提供的信道增益随机变化时具有相关性。此外，EXP3 在<strong>利用</strong>（根据当前信息做出最佳决策的愿望）和 <strong>探索</strong>（尝试可能导致更好结果的新决策的愿望）之间提供了良好的折衷</p>
<p>&nbsp;</p>
<h3 id="gNB-Level"><a href="#gNB-Level" class="headerlink" title="gNB Level"></a>gNB Level</h3><p>由于多智能体场景和大量 UE 的存在，gNodeB 分配级别的场景存在维度爆炸问题，导致状态空间的大小会随着UE的增加而显着增长。因此，使用简单的 RL 框架在计算上变得难以处理。为了克服这一挑战，文章在 gNodeB 分配级别采用<strong>分布式多代理 DRL 方法</strong> [32]，每个 gNodeB 充当独立 DRL agent，将 SDN 控制器预留的 RB 调度到其关联的 UE，并在必要时与其他 gNodeB 合作，在它们之间动态共享未利用的 RB。代理能够通过适当的深度神经网络架构发现有意义的信息，从而学习接近最优的策略</p>
<p>此外，DRL 已被证明可以有效解决无线网络中的许多资源分配问题，例如能量调度 [33] 以及边缘计算和缓存资源的编排 [34]</p>
<p>在详细解释所提出的 SA-MA-RL 算法之前，文章先将每个级别的每个 RB 分配问题建模为了马尔可夫决策过程（MDP），并详细定义了每个 MDP 的主要组成部分</p>
<p>&nbsp;</p>
<h3 id="SDN-资源分配的-MDP-建模"><a href="#SDN-资源分配的-MDP-建模" class="headerlink" title="SDN 资源分配的 MDP 建模"></a>SDN 资源分配的 MDP 建模</h3><p>SDN 资源分配级别的 MDP 由三元组 <code>(Sc,Ac,Rc)</code> 给出，其中 <code>Sc</code> 表示状态空间，<code>Ac</code> 表示动作空间，<code>Rc</code> 是奖励函数</p>
<h4 id="状态空间"><a href="#状态空间" class="headerlink" title="状态空间"></a>状态空间</h4><p>如前所述，SDN agent 被合并到具有网络全局视野的 SDN 控制器中。事实上，SDN agent 的状态包含有关其先前分配给 gNodeB 的 RB 和网络的其他全局参数的信息。其状态空间由如下给出的三维 Sc 组成：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312200317.png" alt="image-20220312200317082"></p>
<p>其中 <code>Kh = &#123;Kb, ∀b ∈ B&#125;</code> 表示上一轮分配给每个 gNodeB 的 RB。B 表示 gNB 集合，K 表示 RB 集合</p>
<h4 id="动作空间"><a href="#动作空间" class="headerlink" title="动作空间"></a>动作空间</h4><p>由于 SDN agent 在一个大的时间尺度上执行 RB 分配，它必须决定应该将哪个子集 Kb ⊆ K 分配给每个 gNodeB b ∈B。请注意，SDN agent 必须确保每次执行 RB 分配时仅将一个 RB 分配给一个 gNodeB。因此，SDN agent 的动作空间，记为 Ac，定义为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312201130.png" alt="image-20220312201130923"></p>
<p>其中动作 <code>ac∈Ac</code> 由行向量 <code>[a1_1,...,a|K|_1 ,a1_2,...,a|K|_2 ,...,a1_|B|,...,a|K|_|B|]</code> 给出。如果向量 <code>ac</code> 的元素 <code>ak_b</code> 等于 1，则表示 SDN agent  决定将 <code>RB_k</code> 分配给 gNodeB b。此外，为了避免将相同的 <code>RB_k</code> 分配给多个 gNodeB，SDN agent 必须确保满足约束 <code>ak_b ≠ ak_b′, ∀k∈K 和 b≠b′∈B</code></p>
<h4 id="奖励函数"><a href="#奖励函数" class="headerlink" title="奖励函数"></a>奖励函数</h4><p>SDN agent 观察环境获得其当前状态后，会从集合 Ac 中选择一个动作 <code>ac</code>，然后收到奖励 Rc。由于目标是最大化数据速率总和，SDN agent 的目标必须与等式 (7a) 中给出的速率总和成正相关，这里文章直接以速率和作为奖励函数了：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312201748.png" alt="image-20220312201748090"></p>
<p>可见 Rc 的值取决于 gNodeB 级别的 RB 分配决策。实际上，SDN agent 的奖励需要等待 gNB 资源分配级别的结果才能获得。因此，RB分配是在两个分配级别之间以联合方式进行的</p>
<p>&nbsp;</p>
<h3 id="gNB-资源分配的-MDP-建模"><a href="#gNB-资源分配的-MDP-建模" class="headerlink" title="gNB 资源分配的 MDP 建模"></a>gNB 资源分配的 MDP 建模</h3><p>gNB 资源分配级别的 MDP 由三元组 <code>(Sb,Ab,Rb)</code> 给出，其中 <code>Sb</code> 表示智能体 b 的状态空间，<code>Ab</code> 表示智能体 b 的动作空间，<code>Rb</code> 是智能体 b 的奖励函数</p>
<h4 id="状态空间-1"><a href="#状态空间-1" class="headerlink" title="状态空间"></a>状态空间</h4><p>如图 2 所示，文章提出了一种多代理 DQL 算法，每个 gNodeB 充当代理，将所需的 RB 分配给 eMBB 和 URLLC 的 UE，并在必要时在 gNodeB 之间共享 RB。实际上，基于 SDN agent 在 SDN 分配级别中选择的操作，每个代理都会观察其本地状态 <code>Sb</code></p>
<p>文章令 SDN 控制器向每个代理传达有关分配给所有其他代理的 RB 的信息。因此，每个代理 b 的状态 <code>Sb</code>，<code>∀b ∈B</code>，由以下元组给出：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312202548.png" alt="image-20220312202548612"></p>
<p>其中 <code>Ub</code> 和 <code>Kb</code> 分别表示与代理 b 相关联的 UE 集和预留给代理 b 的 RB 集。<code>Gb = (G_ub_k: u∈Ub, k∈K)</code> 表示代理 b 及其在每个 RB：k ∈K 中的相关 UE 之间的 DL 信道增益。代理 b 可以很容易地收集信道增益 Gb：</p>
<blockquote>
<p>代理 b 向所有相关的 UE 广播导频信号,然后每个 UE 估计信道状态信息，并通过反馈通道将其发送回相应的代理。在系统中的每个 RB 上，每个关联的 UE 之间的 Gb 估计有助于代理 b 做出正确的决策，尤其是从其他代理借用所需的 RB</p>
</blockquote>
<p>另外，Rmin 为 eMBB 切片要求的最小数据速率阈值、 Dmax 为 URLLC 切片要求的最大延迟阈值</p>
<h4 id="动作空间-1"><a href="#动作空间-1" class="headerlink" title="动作空间"></a>动作空间</h4><p>在 gNodeB 分配级别，每个代理根据自己的分配策略采取行动。代理必须：</p>
<ol>
<li>将预分配的 RB 分配给其相关的 UE </li>
<li>当其预分配的 RB 不足时，向其他代理请求额外的 RB</li>
</ol>
<p>此外，假设每个代理都知道整个系统中存在的 RB 数量。该信息的获取方式如下：在每一轮 SDN 分配级别中，控制器与每个代理通信有关分配给其他代理的 RB 的信息。因此，定义智能体 b 的空间动作 Ab 为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312204028.png" alt="image-20220312204028214"></p>
<p>其中动作 <code>ab ∈ Ab</code> 由行向量 <code>[a1_1,...,a|K|_1 ,a1_2,...,a|K|_2 ,...,a1_|Ub|,...,a|K|_|Ub|]</code></p>
<p>注意，向量 <code>ab</code> 等价于关联矩阵 <code>[xk_ub ]</code>，因为向量 <code>ab</code> 的每个元素 <code>ak_ub</code> 对应于将 RB：k ∈K 分配给关联的UE：ub ∈Ub。换句话说，如果向量 ab 的元素 akub 等于 1，则意味着代理 b 已决定将 RB k 分配给 UE  ub</p>
<p>如果向量 ab 的所有元素 <code>ak&#39;_ub</code> , <code>∀k&#39; ∈K\Kb</code> 都等于 0，则意味着代理 b 不会向其他 gNodeB 请求额外的资源</p>
<p>在构建智能体 b 的动作空间 <code>Ab</code> 时，应遵守约束 (7b)、(7c) 和 (7d)。通过应用这些约束可以显着减少动作空间 <code>Ab</code>，从而在探索阶段显着改善以发现更好的策略，这大大加快了智能体 b 的学习过程</p>
<p>此外，考虑到代理应该合作以在它们之间动态共享未利用的 RB，每个代理将其选择的操作传达给其他代理。因此，每个智能体 b 形成一个联合动作 <code>a= (a_b,a_-b)</code> 其中 <code>a\_-b</code> 表示其他智能体选择的动作</p>
<h4 id="奖励函数-1"><a href="#奖励函数-1" class="headerlink" title="奖励函数"></a>奖励函数</h4><p>多智能体强化学习方法寻求学习一种策略，以实现所有智能体的最大预期总奖励。模型中的主要目标是最大化整个系统的总数据速率，以满足 eMBB 和 URLLC  UE 的 QoS 要求。因此，代理 b 的奖励函数与其总和有关，但要满足 URLLC 服务的超低延迟要求以及 eMBB 服务的最低数据速率要求</p>
<p>代理 b 的奖励取决于它是否已成功地将所需的 RB 分配给其相关的UE。如果选择的动作 <code>ab</code> 满足约束(7b)、(7c)、(7d)、(7e) 和 (7f)，则认为RB分配操作是可行的，否则认为是不可行的操作</p>
<p>约束 (7b)、(7c) 和 (7d) 已经在动作空间构建阶段得到验证，但是由于分配操作可能需要从其他代理借用一些 RB，因此有必要验证借用的 RB 是否：</p>
<ol>
<li>被其所有者利用</li>
<li>还被至少一个除其所有者之外的代理选择</li>
</ol>
<p>由于每个智能体形成联合动作 a，因此 (i) 和 (ii) 可以很容易地被智能体 b 验证。如果其中至少一个是正确的，则不满足约束（7d），因此代理 b 选择的动作是不可行的</p>
<p>因此，智能体 b 的个人奖励用 <code>Rb</code> 表示如下：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312204906.png" alt="image-20220312204906897" style="zoom:85%;" /></p>
<p>当一个动作 <code>ab ∈ Ab</code> 不可行时，它会受到负奖励 <code>Rb = -1</code> 的惩罚，以防止代理在未来选择不可行的动作</p>
<p>&nbsp;</p>
<h3 id="单智能体-EXP3-算法"><a href="#单智能体-EXP3-算法" class="headerlink" title="单智能体 EXP3 算法"></a>单智能体 EXP3 算法</h3><p>为了解决 SDN 分配级别问题，文章采用了基于多武装老虎机（MAB）方法的<strong>在线学习</strong>算法 [31]</p>
<p>在 MAB 中，玩家需要在每一轮游戏中从有限的一组手臂中选择一个手臂，每个手臂都有一个未知的奖励，目标是最大化其预期累积奖励。单代理 MDP 被建模为 MAB，如下所示：</p>
<p>SAN agent（即 SDN 控制器）代表玩家，手臂的集合由其动作空间 Ac 给出。文章提出 EXP3 算法作为一种流行的老虎机策略来解决 SDN 分配级别问题 [2]。 SDN控制器运行 EXP3 算法，每个动作都被分配一个权重，以评估动作对SDN控制器的好坏。动作的权重越高，动作越好。初始时，所有动作的权重均匀分布。然后，该算法迭代几轮。对于每一轮，SDN控制器：</p>
<ol>
<li>计算选择每个动作的概率，该概率与其权重成正比</li>
<li>根据之前计算的概率分布选择一个动作并获得奖励</li>
<li>使用收到的奖励通过<strong>应用指数加权方案</strong>来更新每个动作的权重。这种方案的优点是能迅速增加好动作的概率，并迅速降低坏动作的概率</li>
</ol>
<p>EXP3算法的伪代码：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312221112.png" alt="image-20220312221112891" style="zoom:70%;" /></p>
<p>其中：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312221643.png" alt="image-20220312221643332" style="zoom:80%;" /></p>
<p>EXP3 算法很容易实现，不需要巨大的计算复杂度，因为它只是通过根据其性能增加或减少动作的概率来更新选择动作的权重。注意，EXP3 算法是一种<strong>在线学习</strong>算法，它使 SDN 控制器能够根据从 gNodeB 接收到的反馈来增加或减少动作的权重</p>
<p>准确地说，SDN 控制器选择一个动作 <code>ac,i</code> 将 RB 分配给 gNodeB。然后它等待由 gNodeB 执行的第二个 RB 分配级别的结果。一旦 gNodeB 将 SDN 控制器选择的 RB 分配给其 UE，每个 gNodeB：</p>
<ol>
<li>计算其实现的数据速率</li>
<li>将此信息传达给 SDN 控制器</li>
</ol>
<p>EXP3 算法将使用所有 gNodeB 的总数据速率作为奖励来更新动作的权重</p>
<p>&nbsp;</p>
<h3 id="多智能体-Double-DQN-算法"><a href="#多智能体-Double-DQN-算法" class="headerlink" title="多智能体 Double DQN 算法"></a>多智能体 Double DQN 算法</h3><h4 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h4><p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312205910.png" alt="image-20220312205910922" style="zoom:70%;" /></p>
<p>损失函数定义：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312210909.png" alt="image-20220312210909006"></p>
<p>更新方式：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312210927.png" alt="image-20220312210927890"></p>
<h4 id="推理阶段"><a href="#推理阶段" class="headerlink" title="推理阶段"></a>推理阶段</h4><p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312211613.png" alt="image-20220312211613420" style="zoom:70%;" /></p>
<p>在训练阶段之后，主要Q网络的参数用于在DQL算法的在线实施阶段为 UE 寻找RB分配解决方案。此阶段使用经过训练的代理 DDQN。在每一集的开始，它都会构建每个代理的环境。然后，对于每一步，当观察到一个新状态时，每个智能体 b 选择最大化当前状态 Q 值的动作。一旦所有代理都选择了他们的行动，每个代理就可以形成一个联合行动。从而得到一个RBs分配方案</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2 id="Part5：仿真结果"><a href="#Part5：仿真结果" class="headerlink" title="Part5：仿真结果"></a>Part5：仿真结果</h2><h3 id="实验场景和设置"><a href="#实验场景和设置" class="headerlink" title="实验场景和设置"></a>实验场景和设置</h3><p>考虑支持 SDN 的 RAN 架构，其中 gNodeB 部署在面积为 1Km^2 的正方形中。UE均匀分布在整个覆盖区域，其中每个用户仅与一个 gNodeB 相关联。假定每个 UE 是 eMBB 的 UE 或 URLLC 的 UE。为简单起见，所有 ub ∈ Ub 和 b ∈ B 的传输功率 P_sub 相同</p>
<p>表 I 总结了仿真的关键参数。为了选择有效的 Q 网络模型，训练阶段DQL 算法在配备 Intel Core i7-8750H 处理器、16 GB RAM 和 NVIDIA GeForce GTX 1070 显卡的笔记本电脑上执行。使用 PyTorch 框架创建和训练代理的 DDQN。为了选择最佳的超参数值来训练 DDQN 模型，需要进行大量的模拟。文章在基于文献 [16]、[38] 中的常见设置选择的一组细粒度值中测试了超参数的随机组合</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312212049.png" alt="image-20220312212049040" style="zoom:80%;" /></p>
<center>表 1</center>

<p>特别是，每个 DDQN 由两个完全连接的隐藏层组成，每个隐藏层有 256 个神经元。使用整流线性单元（ReLU）作为激活函数来避免反向传播中的梯度消失问题，从而加速学习过程。 Adam 优化器使用 0.001 的学习率。在训练过程中，每 1000 步将主 Q 网络的权重复制到目标 Q 网络的权重，以避免高估 Q 值</p>
<p>此外还考虑了移动性较低的 UE，因此 gNodeB 和 UE 之间的信道增益在一段时间内保持不变。为此，文章在几个训练集内固定了 UE 的位置，这有助于学习算法更好地获取 UE 的动态，同时稳定训练。 DDQN 的其他超参数在表 II 中给出</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312212213.png" alt="image-20220312212213624" style="zoom:80%;" /></p>
<center>表 2</center>

<p>&nbsp;</p>
<h3 id="DDQN-训练结果"><a href="#DDQN-训练结果" class="headerlink" title="DDQN 训练结果"></a>DDQN 训练结果</h3><p>为了评估所提出的多智能体 DRL 方法的训练性能，文章观察了每个训练集的累积奖励以及训练过程中损失函数的行为</p>
<p>图 3 显示了每轮代理的累积平均奖励。从这个图中看出，累积奖励随着训练集数的增加而提高，当训练集大约达到 1800 时，代理会获得较好体验并开始利用更好的动作。累积奖励接近最大值，表明训练过程在可接受数量的训练集之后收敛。注意，DQL 算法的收敛不会出现大的波动，这主要是由于环境中 UE 的低移动性</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312212435.png" alt="image-20220312212435105" style="zoom:80%;" /></p>
<center>图 3</center>

<hr>
<p>图 4 说明了损失函数 Eq 的收敛性。在 DDQN 的训练过程中，绘制了代理损失结果每轮次的平均值。损失随着训练次数的增加而减少。在前 11 轮中，损失逐渐下降，因为各种新动作是随机探索的，随着学习的进展，基于变得更加可靠的 Q 值函数选择性地执行好的动作。因此，在第 2500 轮之后，损失收敛到最小值，这证明了准确的 Q 值近似效果</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312212612.png" alt="image-20220312212612916" style="zoom:80%;" /></p>
<center>图 4</center>

<hr>
<p>值得注意的是，奖励和损失函数的收敛结果是假设 gNodeB 完全了解信道状态信息得到的，作为DDQN算法的输入。在信道状态信息不完善的情况下，DDQN算法的收敛时间可能会增加[39]。因此，DDQN 算法需要更多的时间才能准确地学习到合适的策略。但是，一旦对 DDQN 算法进行离线训练，就可以快速应用学习到的策略来获得资源分配解决方案</p>
<p>&nbsp;</p>
<h3 id="SA-MA-RL-总模型性能评估"><a href="#SA-MA-RL-总模型性能评估" class="headerlink" title="SA-MA-RL 总模型性能评估"></a>SA-MA-RL 总模型性能评估</h3><p>为了对 SA-MA-RL 总模型进行基准测试，引用文章中实施了两个方案，分别将其称为 3-SRA [10] 和 1-SRA [18] 用于三阶段资源分配和一阶段资源分配</p>
<h4 id="3-SRA"><a href="#3-SRA" class="headerlink" title="3-SRA"></a>3-SRA</h4><p>3-SRA通过考虑两种类型的切片为 UE 分配无线电资源，即速率约束切片（即eMBB切片）和延迟约束切片（即URLLC切片）</p>
<ul>
<li>第一阶段，中央控制器使用启发式算法为每个 gNodeB 中的 eMBB 和 URLLC 切片预留无线电资源（即系统带宽的一部分）</li>
<li>在第二阶段，使用 DRL 算法调整每个 gNodeB 中每个切片的预留无线电资源</li>
<li>最后阶段，采用启发式算法将分配给切片的带宽部分与物理 RB 进行映射</li>
</ul>
<p>选择 3-SRA 作为基准方案是因为它：</p>
<ol>
<li>是一种竞争性方法，以分层方式执行无线电资源的切片操作</li>
<li>可以集成到类似于文章提出的架构的网络架构中，例如，存在具有 RAN 全局视图的中央控制器</li>
<li>考虑两种类型的切片，即 eMBB 切片和 URLLC 切片</li>
<li>基于 DRL 算法来解决无线资源分配问题RAN</li>
</ol>
<h4 id="1-SRA"><a href="#1-SRA" class="headerlink" title="1-SRA"></a>1-SRA</h4><p>1-SRA 使用贪心启发式算法在单阶段过程中将 RB 分配给 UE 。每个 gNodeB 使用此算法将所需的 RB 分配给其关联的 eMBB 和 URLLC  UE </p>
<p>该算法计算 UE 在 gNodeB 的所有可用 RB 上的接收信噪比 (SNR)，然后对于每个 UE：</p>
<ol>
<li>识别由 RB 给出的最高 SNR</li>
<li>计算对应于最高 SNR 的频谱效率 (SE)</li>
<li>计算所需的 RB 数量，即定义为流量队列长度与计算的 SE 的比值</li>
<li>为其分配所需的 RB</li>
</ol>
<p>注意，URLLC  UE 优先于 eMBB  UE ，算法首先调度 URLLC  UE </p>
<p>文章选择 1-SRA 作为基准方案是因为它：</p>
<ol>
<li>考虑了两种类型的切片，即 eMBB 切片和 URLLC 切片</li>
<li>目标函数类似于文中制定的目标函数，使URLLC 和 eMBB  UE 的总数据速率最大化</li>
<li>在问题公式中考虑了 eMBB  UE 的最小数据速率和 URLLC  UE 的最大延迟要求，类似于文中的优化问题</li>
</ol>
<h4 id="效果对比"><a href="#效果对比" class="headerlink" title="效果对比"></a>效果对比</h4><p>文章采用 3-SRA 和 1-SRA 来满足其系统模型的要求</p>
<p>在 3-SRA 中，两个 gNodeB 在 3-SRA 算法下不能为单个 UE 服务</p>
<p>在 1-SRA 中，使用香农速率公式而不是调制和编码方案来计算每个 RB 的可实现数据速率，并且队列长度由每个 UE 的数据包大小给出</p>
<p>为了公平地对 SAM-RL 与 3-SRA 和 1-SRA 的性能进行基准测试，大多数模拟参数的选择与 [10] 和 [18] 中使用的类似。注意，比较结果是 1000 次试验的平均值</p>
<hr>
<p>图 5 显示了在改变 UE 数量时 SA-MA-RL 与基准方法相比的性能，当 UE 数量增加时，SA-MA-RL 始终在目标函数值方面达到最佳性能</p>
<p>注意到，对于这三种方法，代表 URLLC 和 eMBB  UE 的总数据速率值随着 UE 数量的增加而减小。这是由于 UE 在获得足够数量的 RB 以保证其需求方面的竞争力增强。实际上，在 UE 数量较少的情况下，可以将多个 RB 分配给一个 UE ，以保证其在数据速率和延迟方面的要求</p>
<p>另一方面，当 UE 的数量很大时，每种方法都试图为每个 UE 分配最少数量的 RB，以便在数据速率和延迟要求方面满足尽可能多的 UE </p>
<p>SA-MA-RL 比 3-SRA 更好地最大化 UE 的总数据速率，因为 3-SRA 根据整个切片所需的数据速率将 RB 分配给 UE ，切片中包括一组 UE ，而不是单独依赖每个 UE 所需的数据速率。因此，它不能有效地将所需的资源块分配给 UE </p>
<p>而在 1-SRA 方法中，RB 的分配仅基于每个 UE 的最高估计 SNR，这可能很难确定满足 UE  QoS 所需的 RB</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312220424.png" alt="image-20220312220424071" style="zoom:80%;" /></p>
<center>图 5</center>

<hr>
<p>图 6 说明了最小数据速率阈值 (Rmin) 对目标函数 Eq 的影响</p>
<p>基于此结果可知：</p>
<ol>
<li>SA-MA-RL 在所有最小数据速率阈值上都优于 3-SRA 和 1-SRA</li>
<li>最小数据速率阈值越高，SA-MA-RL 与两种基准方法之间的性能差距就越大</li>
</ol>
<p>这是由于在 gNodeB 分配级别提出的多代理方法，当 SDN 控制器预分配的 RB 不足时，gNodeB 可以从其他相邻的 gNodeB 借用 RB。这确实说明了所提出的多智能体方法的有效性并证明了它的鲁棒性</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312220606.png" alt="image-20220312220606871" style="zoom:80%;" /></p>
<center>图 6</center>

<hr>
<p>图 7 显示出 SA-MA-RL 与两种基准方法（即 3-SRA 和 1-SRA）在实现的数据速率大于或等于最小数据速率阈值的 UE 的平均数量方面的比较最小</p>
<p>可以看到，对于所有最小数据速率阈值，SA-MA-RL 始终优于 3-SRA 和 1-SRA。这是因为，在 3-SRA 中，如果给定切片的预留资源不足以提供所需的服务，即最小数据速率阈值，则切片必须等待下一次资源预留更新，而在SA-MA-RL，gNodeB 可以在必要时从其他 gNodeB 请求一些 RB。在 1-SRA 中，如果 SNR 估计不合适，分配给 UE 的 RB 可能不足以提供所需的服务，因此将在下一次资源分配操作中为 UE 提供服务</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312220723.png" alt="image-20220312220723813" style="zoom:80%;" /></p>
<center>图 7</center>

<hr>
<p>在图 8 中，根据数据包所经历的延迟小于或等于最大延迟阈值 Dmax 的 UE 的平均数量，将 SA-MA-RL 的性能与两种基准方法的性能进行了比较</p>
<p>与图 7 中获得的结果类似，可以再次确认，对于所有最大延迟阈值，SA-MA-RL 与 3-SRA 和 1-SRA 相比具有更好的性能</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/20220312220804.png" alt="image-20220312220804350" style="zoom:80%;" /></p>
<center>图 8</center>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Lrk612
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://sharp-rookie.github.io/2022/03/12/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E5%88%A9%E7%94%A8%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93%E5%92%8C%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93RL%E7%9A%84%E6%97%A0%E7%BA%BF%E6%8E%A5%E5%85%A5%E7%BD%91RB%E8%B5%84%E6%BA%90%E5%8A%A8%E6%80%81%E5%88%86%E9%85%8D%E6%A8%A1%E5%9E%8B/" title="一种利用单智能体和多智能体RL的无线接入网RB资源动态分配模型">https://sharp-rookie.github.io/2022/03/12/【论文】一种利用单智能体和多智能体RL的无线接入网RB资源动态分配模型/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/5G/" rel="tag"># 5G</a>
              <a href="/tags/AI/" rel="tag"># AI</a>
              <a href="/tags/Reinforcement-Learning/" rel="tag"># Reinforcement Learning</a>
              <a href="/tags/Mutli-Agent-RL/" rel="tag"># Mutli-Agent RL</a>
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
              <a href="/tags/Resourse-Management/" rel="tag"># Resourse Management</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/03/11/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E5%9F%BA%E4%BA%8E%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84mart%20Multi-RAT%20Access/" rel="prev" title="基于多智能体强化学习的多RAT访问策略&资源调度">
      <i class="fa fa-chevron-left"></i> 基于多智能体强化学习的多RAT访问策略&资源调度
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/03/23/%E3%80%90%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E9%A2%91%E5%9F%9F%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/" rel="next" title="【数字图像处理】频域图像增强">
      【数字图像处理】频域图像增强 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E5%AF%BC%E5%90%91%E5%8F%8A%E7%8E%B0%E6%9C%89%E7%A0%94%E7%A9%B6"><span class="nav-text">问题导向及现有研究</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#NS-amp-SDN-amp-%E9%97%AE%E9%A2%98%E8%83%8C%E6%99%AF"><span class="nav-text">NS &amp; SDN &amp; 问题背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C%E8%B0%83%E7%A0%94"><span class="nav-text">相关工作调研</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%87%E7%AB%A0%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9"><span class="nav-text">文章工作内容</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-2%EF%BC%9A-%E7%B3%BB%E7%BB%9F%E6%A8%A1%E5%9E%8B"><span class="nav-text">Part 2： 系统模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part3%EF%BC%9ARB%E5%88%86%E9%85%8D%E9%97%AE%E9%A2%98%E5%BB%BA%E6%A8%A1-amp-NP-Hard%E5%88%86%E6%9E%90"><span class="nav-text">Part3：RB分配问题建模 &amp; NP-Hard分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%BA%E6%99%AF%E5%BB%BA%E6%A8%A1"><span class="nav-text">场景建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NP-Hard-%E5%88%86%E6%9E%90"><span class="nav-text">NP-Hard 分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part4%EF%BC%9A%E5%9F%BA%E4%BA%8E-Single-Agent-amp-Mutli-Agent-RL-%E7%9A%84%E8%B5%84%E6%BA%90%E5%88%87%E7%89%87"><span class="nav-text">Part4：基于 Single-Agent &amp; Mutli-Agent RL 的资源切片</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SDN-Level"><span class="nav-text">SDN Level</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gNB-Level"><span class="nav-text">gNB Level</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SDN-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E7%9A%84-MDP-%E5%BB%BA%E6%A8%A1"><span class="nav-text">SDN 资源分配的 MDP 建模</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4"><span class="nav-text">状态空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A8%E4%BD%9C%E7%A9%BA%E9%97%B4"><span class="nav-text">动作空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A5%96%E5%8A%B1%E5%87%BD%E6%95%B0"><span class="nav-text">奖励函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gNB-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E7%9A%84-MDP-%E5%BB%BA%E6%A8%A1"><span class="nav-text">gNB 资源分配的 MDP 建模</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4-1"><span class="nav-text">状态空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A8%E4%BD%9C%E7%A9%BA%E9%97%B4-1"><span class="nav-text">动作空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A5%96%E5%8A%B1%E5%87%BD%E6%95%B0-1"><span class="nav-text">奖励函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93-EXP3-%E7%AE%97%E6%B3%95"><span class="nav-text">单智能体 EXP3 算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93-Double-DQN-%E7%AE%97%E6%B3%95"><span class="nav-text">多智能体 Double DQN 算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5"><span class="nav-text">训练阶段</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5"><span class="nav-text">推理阶段</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part5%EF%BC%9A%E4%BB%BF%E7%9C%9F%E7%BB%93%E6%9E%9C"><span class="nav-text">Part5：仿真结果</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E5%9C%BA%E6%99%AF%E5%92%8C%E8%AE%BE%E7%BD%AE"><span class="nav-text">实验场景和设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DDQN-%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C"><span class="nav-text">DDQN 训练结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SA-MA-RL-%E6%80%BB%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="nav-text">SA-MA-RL 总模型性能评估</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-SRA"><span class="nav-text">3-SRA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-SRA"><span class="nav-text">1-SRA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94"><span class="nav-text">效果对比</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Lrk612"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Lrk612</p>
  <div class="site-description" itemprop="description">Lrk's blog</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">61</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.google.com/" title="https:&#x2F;&#x2F;www.google.com" rel="noopener" target="_blank">Google</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://arxiv.org/" title="https:&#x2F;&#x2F;arxiv.org&#x2F;" rel="noopener" target="_blank">arXiv</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://ieeexplore.ieee.org/Xplore/home.jsp" title="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;Xplore&#x2F;home.jsp" rel="noopener" target="_blank">IEEE Xplore</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <!-- 访问量 -->

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 


<!-- 版权 -->
<div class="copyright">
  
  &copy; 2021-12-1 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lrk612</span>
</div>

<!-- ICP备案 -->
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP备案 </a>
      <img src="https://my-picture-1311448338.file.myqcloud.com/img/20211209170739.png" style="display: inline-block;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=2021035798" rel="noopener" target="_blank">豫ICP备2021035798号 </a>
  </div>

<!-- 不知道是什么 -->
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'fH6OdGBcCG8D6jC8NeeJlX9b-gzGzoHsz',
      appKey     : '1UoIb6vszMw6wl0n7kreb4Xz',
      placeholder: "Just go go ^_^",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
    var infoEle = document.querySelector('#comments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0){
      infoEle.childNodes.forEach(function(item) {
        item.parentNode.removeChild(item);
      });
    }
  }, window.Valine);
});
</script>

</body>
</html>
