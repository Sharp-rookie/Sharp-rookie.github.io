<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sharp-rookie.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

<script> 
   (function(){
          if(''){
              if (prompt('请输入文章密码') !== ''){
                  alert('密码错误！');
                  history.back();
              }
          }
      })();
  </script>
  <meta name="description" content="&amp;emsp;&amp;emsp;针对退化的人脸图像恢复问题，常见的方法有使用DNN端到端训练的，也有使用Style GAN等GAN模型进行重建的。最近比较流行的是既使用GAN来生成细节纹理，又融合DNN提取的特征来保证结构一致。 &amp;emsp;&amp;emsp;本文设计了能够识别退化程度，并动态调整融合比例的网络模型 Panini-NET 具体工作：  提出了一种无监督退化表示学习策略，用于提取退化图像的判别退化">
<meta property="og:type" content="article">
<meta property="og:title" content="一种人脸图像恢复的融合方案">
<meta property="og:url" content="https://sharp-rookie.github.io/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/index.html">
<meta property="og:site_name" content="最忆是江南">
<meta property="og:description" content="&amp;emsp;&amp;emsp;针对退化的人脸图像恢复问题，常见的方法有使用DNN端到端训练的，也有使用Style GAN等GAN模型进行重建的。最近比较流行的是既使用GAN来生成细节纹理，又融合DNN提取的特征来保证结构一致。 &amp;emsp;&amp;emsp;本文设计了能够识别退化程度，并动态调整融合比例的网络模型 Panini-NET 具体工作：  提出了一种无监督退化表示学习策略，用于提取退化图像的判别退化">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252005780.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252005780.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252016095.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252019687.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252022579.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252037238.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252036996.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252042896.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252044385.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252044185.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252045987.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252049281.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252051931.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252108302.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252115982.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252114479.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252119507.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252120373.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252139368.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252139183.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252143167.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252144320.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252147189.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252148683.png">
<meta property="og:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252150151.png">
<meta property="article:published_time" content="2022-06-25T13:54:31.070Z">
<meta property="article:modified_time" content="2022-06-26T05:15:09.900Z">
<meta property="article:author" content="Lrk612">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="GAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://my-picture-1311448338.file.myqcloud.com/img/202206252005780.png">

<link rel="canonical" href="https://sharp-rookie.github.io/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>一种人脸图像恢复的融合方案 | 最忆是江南</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
        <a target="_blank" rel="noopener" href="https://github.com/Sharp-rookie" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">最忆是江南</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Love actually is all around</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th-list fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-papers">

    <a href="/papers/" rel="section"><i class="fa fa-book fa-fw"></i>论文阅读</a>

  </li>
        <li class="menu-item menu-item-friendlink">

    <a href="/friendlink/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sharp-rookie.github.io/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Lrk612">
      <meta itemprop="description" content="Lrk's blog">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="最忆是江南">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          一种人脸图像恢复的融合方案
        </h1>

        <div class="post-meta">
         
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-06-25 21:54:31" itemprop="dateCreated datePublished" datetime="2022-06-25T21:54:31+08:00">2022-06-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
            </span>

          
            <span id="/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/" class="post-meta-item leancloud_visitors" data-flag-title="一种人脸图像恢复的融合方案" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>&emsp;&emsp;针对退化的人脸图像恢复问题，常见的方法有使用DNN端到端训练的，也有使用Style GAN等GAN模型进行重建的。最近比较流行的是既使用GAN来生成细节纹理，又融合DNN提取的特征来保证结构一致。</p>
<p>&emsp;&emsp;本文设计了能够识别退化程度，并动态调整融合比例的网络模型 Panini-NET</p>
<p><strong>具体工作：</strong></p>
<ul>
<li>提出了一种无监督退化表示学习策略，用于提取退化图像的判别退化表示</li>
<li>提出了一种退化感知特征插值模块，可以根据退化表示的情况来动态融合图像特征和 GAN Prior 的两种类型信息</li>
</ul>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252005780.png" alt="image-20220625200552618" style="zoom: 35%;" /></p>
<p><strong>原文</strong></p>
<p><a target="_blank" rel="noopener" href="https://lrk612.com/resources/Panini-Net GAN Prior Based Degradation-Aware Feature Interpolation for Face Restoration.pdf">Panini-Net GAN Prior Based Degradation-Aware Feature Interpolation for Face Restoration</a></p>
<span id="more"></span>
<p>&nbsp;</p>
<h1 id="文章概述"><a href="#文章概述" class="headerlink" title="文章概述"></a>文章概述</h1><p>&emsp;&emsp;人脸恢复（FR）通常是一个不适定的图像逆问题，尤其是在高度退化或多重退化的情况下（例：下采样、噪声、模糊和压缩）。</p>
<p><strong>相关研究进展</strong></p>
<ul>
<li><p>传统的基于深度网络的方法通常利用单一模型进行端到端训练，<strong>可以很好地掌握整体结构，但缺乏丰富的细节</strong></p>
</li>
<li><p>由于近年来 GAN 模型的出色表现，一些工作使用预训练 GAN 模型作为 FR 任务的 GAN Prior。通过将退化的人脸图像编码到预训练的 GAN 的潜在空间中，从而利用隐含在 GAN Prior 中的丰富细节</p>
<p>  虽然<strong>实现了高视觉质量</strong>，但是由于潜在空间维度低，空间表达能力差，这些方法往往<strong>无法完全捕捉退化人脸图像的人脸结构，复原的图像里可能并不是同一个人</strong></p>
</li>
<li><p>为了进一步捕捉退化人脸图像的人脸结构信息，同时保留 GAN Prior 的真实性，一些方法不仅将退化的人脸图像编码进潜在空间，同时也将外部特征（例：从退化的人脸图像中提取的特征）与 GAN Prior 特征融合</p>
<p>  与仅仅基于 GAN Prior 的 FR 方法相比，这些方法<strong>在身份一致性方面取得了显着改进</strong>。但是它们<strong>没有为退化感知特征融合提供明确的设计方案</strong>，因此在面对不同的退化水平时导致视觉质量的<strong>鲁棒性不足</strong></p>
</li>
</ul>
<p><strong>本文所作工作：</strong></p>
<ul>
<li><p>提出了一种退化表示的无监督学习策略，可提取图像的退化表示（DR），作为动态融合的全局条件</p>
</li>
<li><p>提出了一种退化感知特征插值（DAFI）模块，可以根据退化表示（DR）的情况来动态融合图像特征和 GAN Prior 的两种类型信息</p>
</li>
<li><p>提出了一种新颖的基于 GAN Prior 的退化感知特征插值网络，Panini-Net。用于融合上面两个模块的功能，能考虑到各种退化水平，平衡真实性和保真度</p>
</li>
<li><p>对 多退化人脸恢复 和 16倍超分辨率 这两个任务进行了测试，验证 Panini-Net 取得最好的效果</p>
</li>
</ul>
<p>&emsp;&emsp;值得一提的是，之所以称作 “Panini”，是因为融合的想法类似于制作 Panini 的方式。具体而言，轻度退化的人脸图像包含丰富的有效信息，所以 Panini-Net 将增加退化图像特征的融合比例，并降低 GAN Prior 特征的融合比例；退化严重的人脸图像缺乏有效信息，所以 Panini-Net 会降低退化图像特征的融合比例，同时增加 GAN Prior 特征的比例。</p>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h3 id="GAN-Prior"><a href="#GAN-Prior" class="headerlink" title="GAN Prior"></a>GAN Prior</h3><p>&emsp;&emsp;近年来以 Style-GAN 为代表的 GAN 可以生成高分辨率图像，启发了很多基于 GAN Prior 的图像编辑工作。这些方法通常通过 GAN Inversion 实现图像编辑。具体而言，输入图像首先作为潜在代码嵌入到 StyleGAN 的潜在空间，然后通过控制潜在代码来实现图像编辑，如超分辨率、修复、属性转换等。</p>
<p>&emsp;&emsp;然而，潜在代码编辑一般不能很好地捕捉空间结构。因此，输入图像和编辑图像之间的身份通常不一致。不过即便如此，潜码编辑的优势依然明显，生成的图像质量高，细节逼真。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>代表性工作</th>
<th>内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>PULSE (Menon et al. 2020)</td>
<td>优化了 StyleGAN 的潜在代码来解决图像超分辨率任务</td>
</tr>
<tr>
<td>PSP (Richardson et al. 2021)</td>
<td>训练编码器直接预测潜在代码而不是迭代优化，从而加快推理时间</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;考虑到 StyleGAN 的图像真实性和基于 DNN 方法的图像结构保真能力，最近的一些方法将这两个优点结合起来，把图像的外部结构特征融合到预训练 StyleGAN 的中间特征中。</p>
<p>&emsp;&emsp;与之前仅仅基于 GAN Prior 的 FR 方法相比，这些方法在身份一致性方面有明显改进，但它们没有针对不同退化水平时的动态特征融合进行明确设计，因此在面临严重退化时，图像视觉质量的鲁棒性不足。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>代表性工作</th>
<th>内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPEN (Yang et al. 2021)</td>
<td>退化图像作为输入，中间特征作为输入噪声，预训练的 StyleGAN2 Generator作为解码器</td>
</tr>
<tr>
<td>GLEAN (Chan et al. 2021)</td>
<td>使用 StyleGAN2 Generator作为潜在库，并使用 编码器-潜在库-解码器 框架来实现超分辨率，每个部分之间连接的特征以连接卷积的方式融合</td>
</tr>
<tr>
<td>GFP-GAN (Wang et al. 2021b)</td>
<td>使用退化去除模块来预测潜在代码并提取中间特征来调制 StyleGAN 特征。退化去除模块用监督学习，并且 GAN 对眼睛和嘴巴分别进行训练以提高质量</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;在 Image2StyleGAN++ 的工作中，作者发现编辑 Style-GAN 的“激活张量”可以实现更精确的空间编辑。也有工作在潜在代码的较低层进行样式混合以迁移目标身份。这些工作表明 StyleGAN 的底层对粗略结构的影响更大，而高层主要对图像细节有贡献。 StyleGAN 的这些特性启发本文作者通过编辑 StyleGAN 的底部特征来解决 FR 任务，从而既实现身份一致性，又能保证较高层不受影响，以保留纹理和面部细节。</p>
<h3 id="Contrastive-Learning"><a href="#Contrastive-Learning" class="headerlink" title="Contrastive Learning"></a>Contrastive Learning</h3><p>&emsp;&emsp;最近，对比学习在无监督的表征学习上有长足发展。一些方法开始将对比学习用于图像生成任务。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>代表性工作</th>
<th>内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>DASR (Wang et al. 2021a)</td>
<td>用 MoCo 框架对退化编码器进行预训练以学习退化表示，然后使用退化表示来指导网络执行超分辨率任务。在退化编码器的预训练中，从同一张退化图像中随机选择两个补丁，一个补丁作为另一个补丁的正例。这两个补丁共享相同的退化功能，而内容也可能相似。因此，退化编码器不仅可以学习退化表示，还可以学习内容表示。</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;此外，大光圈拍摄的人像照片中，景深 (DOF) 效果会导致背景模糊。如果上述工作中提到的“补丁”恰好位于背景部分，退化编码器可能就难以区分背景模糊是由自由度还是由退化引起的。因此，本文设计了一种无监督退化表示学习（UDRL）策略，专注于学习退化人脸图像的整体退化表示，并鼓励学习退化而不是图像本身的内容。</p>
<h3 id="Visual-Attention"><a href="#Visual-Attention" class="headerlink" title="Visual Attention"></a>Visual Attention</h3><p>&emsp;&emsp;视觉注意力通常用于提高 CNN 的性能，不仅可以判断出关注点在哪里，还可以提高兴趣区域的表示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>代表性工作</th>
<th>内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>Hu, Shen, and Sun 2018</td>
<td>提出了 Squeeze-and-Excitation (SE) 模块，通过显式建模通道之间的相互依赖关系来自适应地调整通道特征权重</td>
</tr>
<tr>
<td>Woo et al. 2018</td>
<td>提出了卷积块注意模块 (CBAM) ，明确地结合了通道注意力和空间注意力</td>
</tr>
<tr>
<td>Li et al. 2019</td>
<td>提出了选择性内核 (SK) 单元，根据感兴趣区域自适应地调整感受野大小</td>
</tr>
</tbody>
</table>
</div>
<p>&emsp;&emsp;上述方法为通用视觉任务提供了 Baseline。但是都是从需要处理的局部特征中提取注意力。而在 FR 模型中，这些特征可能几乎不包含有效的退化信息。此外，它们只能强化单一来源的特征，而本文的迫切需求是动态融合两种来源的特征（即 GAN Prior 的特征和图像中提取的特征）。为了克服这些缺陷，本文提出的 DAFI 模块直接从退化的人脸图像中提取<strong>全局条件</strong>，并对来自不同来源的特征实施自适应特征融合。</p>
<h1 id="Panini-Net"><a href="#Panini-Net" class="headerlink" title="Panini-Net"></a>Panini-Net</h1><p><strong>Panini-Net 组成部分：</strong></p>
<ul>
<li>图像特征提取模块</li>
<li>作为 GAN Prior 模块的预训练人脸 GAN 模型（例如 StyleGAN2）</li>
<li>退化感知特征组成插值模块</li>
</ul>
<p><strong>执行流程：</strong></p>
<ul>
<li>给定一张退化的图像 <code>X</code>，其退化表示 (DR) 由预训练的退化表示编码器 (DRE) 编码为 <code>V_DR</code></li>
<li>图像特征提取模块从退化的人脸图像中提取特征 <code>F_IFE</code> 并生成潜在代码 <code>w+</code></li>
<li><code>w+</code> 可以从 GAN Prior 模块中粗略地获取类似的高质量人脸</li>
<li>然后退化感知特征插值模块将特征 <code>F_IFE</code> 逐步插值到 GAN Prior 特征中，以对提取的相似人脸的人脸结构进行校正</li>
<li>最终获得具有真实性和身份一致性的高质量人脸图像 <code>Y</code></li>
</ul>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252005780.png" alt="image-20220625200552618"></p>
<center>图中传递的中间变量 F 都具有相同的shape</center>



<h2 id="Part1：图像特征提取"><a href="#Part1：图像特征提取" class="headerlink" title="Part1：图像特征提取"></a>Part1：图像特征提取</h2><p>图像特征提取模块从退化的人脸图像中提取特征 <code>F_IFE</code> 并生成潜在代码 <code>w+</code>。给定输入图像 X，图像特征提取器 (IFE) 逐步提取初步特征 <code>Fi_IFE ∈ R_Ci×Hi×Wi</code>：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252016095.png" alt="image-20220625201605049" style="zoom:50%;" /></p>
<center>H6 是 desen block，其他 H 都是一层卷积</center>

<p>为了避免相邻特征的耦合，文章增加了额外的卷积分支来进一步提取特征 <code>Fi_IFE ∈ R_Ci×Hi×Wi</code> 作为融合的最终特征：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252019687.png" alt="image-20220625201951645" style="zoom:50%;" /></p>
<center>这里 H 都只是一层卷积层，文章已验证这样做是有效的</center>

<p>最后，使用由卷积层和全连接层组成的潜码编码器（LCE）来预测潜码 <code>w+ ∈ R_18×512</code>，表示为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252022579.png" alt="image-20220625202213542" style="zoom:50%;" /></p>
<h2 id="Part2：GAN-Prior"><a href="#Part2：GAN-Prior" class="headerlink" title="Part2：GAN Prior"></a>Part2：GAN Prior</h2><p>以预训练的 StyleGAN2 生成器作为 GAN Prior 模块 (GPM)。具体而言，GPM 从学习常数特征 Finit 开始，然后将逐次插值后的 F 传递给一系列 GAN Prior 块（GPBi, i ∈ {1, …, 5 }）。</p>
<p>每个 GPBi 都包含一个上采样操作（GPB1 除外）并输出特征 <code>Fi_GPB</code> 。潜在代码 <code>w+</code> 可以从 GPM 中粗略地获取相似的高质量人脸。</p>
<p>特征 <code>Fi_GPB, i ∈ &#123;1,...,5&#125;</code> 输入退化感知特征插值模块进行动态融合，以纠正面部结构。为了保留精致的面部细节，文章保留了 GPM 的其余部分不变。</p>
<h2 id="Part3：退化感知特征插值"><a href="#Part3：退化感知特征插值" class="headerlink" title="Part3：退化感知特征插值"></a>Part3：退化感知特征插值</h2><p>退化感知特征插值（DAFI）模块由退化表示编码器（DRE）和几个 DAFI 块（DAFIi，i ∈ {1，…，5}）组成。</p>
<p>DRE 负责提取退化的人脸图像的退化表示（DR）。文章采用无监督退化表示学习（UDRL）策略来预训练 DRE。通过在两个不同的图像上应用相同的退化函数来获得两个退化的图像 <code>X_query</code> 和 <code>X_key</code>。然后以 <code>X_key</code> 为正例，使用 MoCo (Chen et al. 2020c) 框架进行对比训练。</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252037238.png" alt="image-20220625203758178" style="zoom:50%;" /></p>
<p>将 <code>X_query</code> 作为 Encoder 的输入以生成向量 <code>q</code>，并将 <code>X_key</code> 作为 Momentum Encoder 的输入以生成向量 <code>k0</code>。 Momentum Encoder 生成的历史可以形成一个队列 <code>k0, k1, ..., kn</code>。对于每个 <code>q</code>，由于 <code>k0</code> 是从与 <code>X_query</code> 共享相同退化模式的 <code>X_key</code> 生成的，所以向量 <code>k0</code> 应该与 <code>q</code> 相似，而队列中的其余向量应该与 <code>q</code> 不同。 使用 <strong>InfoNCE</strong> 作为损失函数，鼓励 <code>q</code> 的编码接近 <code>k0</code> 并远离 <code>k1，k2，...，kn</code>，公式为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252036996.png" alt="image-20220625203648942" style="zoom:50%;" /></p>
<p>在使用 UDRL 策略预训练 DRE 后，冻结 DRE 并微调 Panini-Net。给定一个退化的图像 <code>X</code>，其退化表示（DR）被有效地编码为一个向量 <code>V_DR ∈ R1×256</code>：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252042896.png" alt="image-20220625204222857" style="zoom:50%;" /></p>
<p>对于由 GPBi 生成的每个特征 <code>Fi_GPB，i ∈ &#123;1,...,5&#125;</code>，用一个专用的 DAFi 块来合并其对应的 <code>Fi_IFE</code> 的有效面部结构信息。</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252044385.png" alt="image-20220625204439327" style="zoom:50%;" /></p>
<p>给定 <code>V_DR</code> 作为全局条件，每个 DAFi 块首先包含一个专用的 MLP，然后是 Softmax，生成一个自适应降级感知通道掩码 <code>i ∈ R1×Ci , i ∈ &#123;1,...,5&#125;</code>，即：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252044185.png" alt="image-20220625204449150" style="zoom:50%;" /></p>
<p>显然，<code>maski</code> 是一个维数等于待插值特征的通道数的向量，向量 mask 的每个元素代表某个通道的一个插值权重。然后图像特征和GAN Prior 之间的退化感知插值公式为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252045987.png" alt="image-20220625204556944" style="zoom:50%;" /></p>
<center>其中⊙表示沿通道维度做矩阵数乘</center>

<p>接下来，将 <code>Fi_GPB</code> 替换为 <code>Fi_DAFi</code> 作为第 (i + 1) 个 GAN 先验块 GPBi+1 的输入，i ∈ {1, …, 5}，即：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252049281.png" alt="image-20220625204938237" style="zoom:50%;" /></p>
<p>最终结果 Y 由最后一个块 GPB9 生成：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252051931.png" alt="image-20220625205149888" style="zoom:50%;" /></p>
<h3 id="训练步骤-amp-损失函数"><a href="#训练步骤-amp-损失函数" class="headerlink" title="训练步骤 &amp; 损失函数"></a>训练步骤 &amp; 损失函数</h3><p><strong>训练步骤：</strong></p>
<ol>
<li>通过 UDRL 策略预训练 DRE</li>
<li>加载预训练的 StyleGAN2 Generator作为GPM</li>
<li>微调整个 Panini-Net 网络，例如 DRE 的参数</li>
</ol>
<p><strong>损失函数：</strong></p>
<p>使用 L1 loss、VGG perceptual loss 和 adversarial loss。 StyleGAN2 的预训练鉴别器也用于对抗性训练。</p>
<h1 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h1><p>为了验证 Panini-Net 在不同 FR 任务上的效用，文章对两个典型的 FR 任务进行了广泛的实验：多退化人脸恢复、人脸超分辨率</p>
<h2 id="多退化人脸恢复"><a href="#多退化人脸恢复" class="headerlink" title="多退化人脸恢复"></a>多退化人脸恢复</h2><p><strong>训练：</strong></p>
<p>在 FFHQ 数据集上训练 Panini-Net，包含 70000 个高质量（HQ）人脸图片。并用 (Yang et al. 2021; Wang et al. 2021b) 中的实现方案，通过经典的退化函数来合成退化的低质量 (LQ) 图像：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252108302.png" alt="image-20220625210837251" style="zoom:50%;" /></p>
<p>具体操作为：</p>
<ol>
<li>HQ 图像 Y 由高斯模糊核 k 进行卷积，模糊核大小 σ 是随机选择</li>
<li>下采样（使用对称上采样以保持尺寸不变），参数 r 从 [10:200] 随机选择</li>
<li>加上加性噪声，参数 δ 从 [0:25] 随机选择</li>
<li>做质量因子为 q 的 JPEG 压缩，参数 q 从 [5:50]  随机选择</li>
</ol>
<p>由此生成用于训练的 HQ-LQ 图像对。 LQ 和 HQ 图像的尺寸分别为 512×512 和 1024×1024。</p>
<p>文章采用 Adam 优化器和余弦退火方案对 Panini-Net 进行微调，batch size 为 8，迭代次数为 600K</p>
<p><strong>测试：</strong></p>
<p>文章在 CelebA-HQ (Karras et al. 2018) 数据集中随机选择 1000 张 HQ 人脸图像作为 ground truth (GT)，然后使用上述退化函数处理作为输入。然后将 Panini-Net 与最近最先进的基于 GAN Prior 的 FR 方法进行比较，包括官方预训练的 GFP-GAN (Wang et al. 2021b) 和 GPEN (Yang et al. 2021) 模型。注意，这些对比方法都使用 StyleGAN2 作为 GAN Prior，并使用相同的退化公式用于合成 LQ 图像。</p>
<p>使用 PSNR、FID (Heusel et al. 2017)、LPIPS (Zhang et al. 2018a) 作为定量比较的指标，对比如下：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252115982.png" alt="image-20220625211501934" style="zoom:50%;" /></p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252114479.png" alt="image-20220625211444181" style="zoom:50%;" /></p>
<p>Panini-Net 在图像真实性和身份一致性之间的平衡方面的明显优势。即使退化严重，Panini-Net 恢复的图像在视觉质量上也可以与原图相媲美。</p>
<h2 id="人脸超分辨率"><a href="#人脸超分辨率" class="headerlink" title="人脸超分辨率"></a>人脸超分辨率</h2><p><strong>训练：</strong></p>
<p>因为固定比率下采样认为是一种恒定的退化，所以不需要 DRE 来提取退化表示。文章为 16 倍 SR 任务简化了 Panini-Net 的设计：</p>
<ol>
<li>移除 DRE 并用可学习的常数向量表示 V_DR</li>
<li>调整一些相关的卷积以适应输入图像的新尺寸</li>
</ol>
<p>在此实验中，文章使用 FFHQ 数据集作为 GT，并使用 16 倍双线性插值作为下采样操作来生成低分辨率（LR）图像，从而形成 GT-LR 对进行训练。LR图像的大小为64×64，GT 为 1024×1024，对应于修改后的 Panini-Net 的输入和输出大小。</p>
<p><strong>测试：</strong></p>
<p>使用相同的方法从 CelebA-HQ 生成测试数据集，并将 Panini-Net 与测试数据集上最近基于 SOTA GAN Prior 的 SR 方法进行比较，其也使用 Style-GAN2 作为 GAN Prior。</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252119507.png" alt="image-20220625211933459" style="zoom:50%;" /></p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252120373.png" alt="image-20220625212005107" style="zoom:50%;" /></p>
<h1 id="消融学习"><a href="#消融学习" class="headerlink" title="消融学习"></a>消融学习</h1><h2 id="与不同特征融合的比较"><a href="#与不同特征融合的比较" class="headerlink" title="与不同特征融合的比较"></a>与不同特征融合的比较</h2><p>基于 GAN Prior 的 FR 方法通常通过将外部特征融合到 GAN Prior 的特征中来实现身份一致性。连接后卷积（文中简称为 Cat-Conv）是一种典型的特征融合方法，GLEAN 也采用了这种方法。给定来自不同来源的两个信息特征，它首先通过通道将它们连接起来，然后使用卷积层来减少通道数。这里文章简单地将 Panini-Net 中的 DAFI 替换为 Cat-Conv。为了排除 DRE 的影响，只在在 16 倍 SR 任务（没有 DRE）上使用 Cat-Conv 训练 Panini-Net，训练设置与 Panini-Net 相同。结果如图、表所示：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252139368.png" alt="image-20220625213924236" style="zoom:50%;" /></p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252139183.png" alt="image-20220625213939677" style="zoom:50%;" /></p>
<p>虽然 Cat-Conv 比 DAFI 有更多参数，但它在应用于 Panini-Net 时会导致性能下降，尤其是在细节视觉质量（例如牙齿和眼睛）方面。文章认为这是因为 DAFI 中的插值操作可以更好地保留 GAN Prior 特征中封装的细节，而全局条件引导可以帮助 DAFI 更好地处理特征融合。</p>
<h2 id="Panini-Net-剖析"><a href="#Panini-Net-剖析" class="headerlink" title="Panini-Net 剖析"></a>Panini-Net 剖析</h2><p>为了研究退化水平和插值率之间的相关性，文章在方程中固定了 σ、δ、q。同时选择下采样率 r 分别为 16、32、64、128。然后得到四组退化函数，这些退化函数之间的唯一区别在于下采样率 r。然后使用这四个函数处理单个 HQ 图像，得到四个退化的人脸图像 <code>&#123;X↓16，X↓32，X↓64，X↓128&#125;</code>，它们实际内容相同，但退化程度不同。</p>
<h3 id="退化感知效果测试"><a href="#退化感知效果测试" class="headerlink" title="退化感知效果测试"></a>退化感知效果测试</h3><p>将这四个图像分别输入到 Panini-Net 中。由于 Panini-Net 采用逐层渐进式插值，靠前的 <code>DAFIi, i ∈ &#123;1, ..., 5&#125;</code> 影响较弱，而 DAFI5 对恢复的影响更大。因此，对于每个退化的人脸图像，只记录 DAFI5 的插值掩码。为简单起见，将 <code>mask5 ∈ R1×512</code> 的所有元素相加，然后除以维度，得到范围 (0,1) 内的比率 θ，定义为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252143167.png" alt="image-20220625214353069" style="zoom:50%;" /></p>
<p>显然，θ 可以粗略地反映特征 <code>F5_GPB</code> 的使用率。记录如表所示：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252144320.png" alt="image-20220625214434231" style="zoom:50%;" /></p>
<p>在 DAFI5 中，θ 与退化水平呈明显的正相关关系：当退化变得严重时，θ 会增加。这意味着当退化变得严重时，Panini-Net 倾向于利用更多的 GAN Prior 信息，符合预期。</p>
<h3 id="GAN-Prior-和-特征提取器-效果测试"><a href="#GAN-Prior-和-特征提取器-效果测试" class="headerlink" title="GAN Prior 和 特征提取器 效果测试"></a>GAN Prior 和 特征提取器 效果测试</h3><p>此外，还希望看到功能 <code>F_GPB</code> 和 <code>F_IFE</code> 在面对不同的退化水平时对最终结果有何贡献。</p>
<p>将 {X↓16, X↓32, X↓64, X↓128} 分别输入 Panini-Net。第一轮得到标准结果 Y，第二轮在推理过程中手动将 <code>F_GPB</code> 设置为零以获得结果 <code>Y_IFE</code> ，DAFI 的操作可以表述为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252147189.png" alt="image-20220625214721087" style="zoom:50%;" /></p>
<center>即只有DNN提取的特征，没有GAN Prior部分</center>

<p>在第三轮在推理过程中手动将 <code>F_IFE</code> 设置为零，得到结果 <code>Y_GPB</code> ，DAFI 的操作可以表述为：</p>
<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252148683.png" alt="image-20220625214859559" style="zoom:50%;" /></p>
<center>即只有GAN Prior，没有DNN提取的特征部分</center>

<p><img src="https://my-picture-1311448338.file.myqcloud.com/img/202206252150151.png" alt="image-20220625215002303" style="zoom:50%;" /></p>
<p>结果如图所示。当退化变得严重时，<code>Y_IFE</code> 的有效内容会下降，而 <code>Y_GPB</code> 会变得更加完整，这意味着 PaniniNet 可以动态增加使用 GAN Prior 来补偿退化的人脸图像中有效内容的损失。此外，当退化较轻时，<code>Y_IFE</code> 的内容主要是关于输入图像的粗略结构，而 <code>Y_GPB</code> 的内容主要是关于眼睛、鼻子、嘴巴和纹理的细化。这表明 Panini-Net 模型学会了如何从 GAN Prior 和退化的人脸图像中提取有效信息。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Lrk612
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://sharp-rookie.github.io/2022/06/25/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E4%BA%BA%E8%84%B8%E5%9B%BE%E7%89%87%E6%81%A2%E5%A4%8D%E7%9A%84%E8%9E%8D%E5%90%88%E6%96%B9%E6%A1%88/" title="一种人脸图像恢复的融合方案">https://sharp-rookie.github.io/2022/06/25/【论文】一种人脸图片恢复的融合方案/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/GAN/" rel="tag"># GAN</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/06/25/%E5%8F%98%E6%8D%A2%E6%80%BB%E7%BB%93/" rel="prev" title="时域频域的各种变换公式">
      <i class="fa fa-chevron-left"></i> 时域频域的各种变换公式
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/07/09/%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91%E4%B8%80%E7%A7%8D%E7%BC%96%E7%A0%81%E7%BC%93%E5%AD%98%E5%88%86%E5%B8%83%E5%86%B3%E7%AD%96%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%A1%88/" rel="next" title="一种编码缓存分布决策的优化方案">
      一种编码缓存分布决策的优化方案 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%87%E7%AB%A0%E6%A6%82%E8%BF%B0"><span class="nav-text">文章概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="nav-text">相关工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GAN-Prior"><span class="nav-text">GAN Prior</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Contrastive-Learning"><span class="nav-text">Contrastive Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visual-Attention"><span class="nav-text">Visual Attention</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Panini-Net"><span class="nav-text">Panini-Net</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Part1%EF%BC%9A%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">Part1：图像特征提取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part2%EF%BC%9AGAN-Prior"><span class="nav-text">Part2：GAN Prior</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part3%EF%BC%9A%E9%80%80%E5%8C%96%E6%84%9F%E7%9F%A5%E7%89%B9%E5%BE%81%E6%8F%92%E5%80%BC"><span class="nav-text">Part3：退化感知特征插值</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%AD%A5%E9%AA%A4-amp-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">训练步骤 &amp; 损失函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C"><span class="nav-text">对比实验</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E9%80%80%E5%8C%96%E4%BA%BA%E8%84%B8%E6%81%A2%E5%A4%8D"><span class="nav-text">多退化人脸恢复</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%BA%E8%84%B8%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87"><span class="nav-text">人脸超分辨率</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AD%A6%E4%B9%A0"><span class="nav-text">消融学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8E%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-text">与不同特征融合的比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Panini-Net-%E5%89%96%E6%9E%90"><span class="nav-text">Panini-Net 剖析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%80%E5%8C%96%E6%84%9F%E7%9F%A5%E6%95%88%E6%9E%9C%E6%B5%8B%E8%AF%95"><span class="nav-text">退化感知效果测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GAN-Prior-%E5%92%8C-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%99%A8-%E6%95%88%E6%9E%9C%E6%B5%8B%E8%AF%95"><span class="nav-text">GAN Prior 和 特征提取器 效果测试</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Lrk612"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Lrk612</p>
  <div class="site-description" itemprop="description">Lrk's blog</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.google.com/" title="https:&#x2F;&#x2F;www.google.com" rel="noopener" target="_blank">Google</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://arxiv.org/" title="https:&#x2F;&#x2F;arxiv.org&#x2F;" rel="noopener" target="_blank">arXiv</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://ieeexplore.ieee.org/Xplore/home.jsp" title="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;Xplore&#x2F;home.jsp" rel="noopener" target="_blank">IEEE Xplore</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        <!-- 访问量 -->

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 


<!-- 版权 -->
<div class="copyright">
  
  &copy; 2021-12-1 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lrk612</span>
</div>

<!-- ICP备案 -->
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">ICP备案 </a>
      <img src="https://my-picture-1311448338.file.myqcloud.com/img/20211209170739.png" style="display: inline-block;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=2021035798" rel="noopener" target="_blank">豫ICP备2021035798号 </a>
  </div>

<!-- 不知道是什么 -->
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'fH6OdGBcCG8D6jC8NeeJlX9b-gzGzoHsz',
      appKey     : '1UoIb6vszMw6wl0n7kreb4Xz',
      placeholder: "Just go go ^_^",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
    var infoEle = document.querySelector('#comments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0){
      infoEle.childNodes.forEach(function(item) {
        item.parentNode.removeChild(item);
      });
    }
  }, window.Valine);
});
</script>

</body>
</html>
